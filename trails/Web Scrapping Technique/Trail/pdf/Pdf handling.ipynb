{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab4faa16-03e3-47e4-a84d-a1c6d5aa2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2 as pdf\n",
    "\n",
    "from PyPDF2  import PdfReader,PdfWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa118876-fc85-486b-bb64-4e4dd31e8994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<PyPDF2._reader.PdfReader object at 0x00000238DBD14160> \n",
      "\n",
      "length of pdf 69\n"
     ]
    }
   ],
   "source": [
    "with open(\"ProjectReport .pdf\",'rb') as file:\n",
    "    # create pdf reader object\n",
    "    \n",
    "    pdf_reader = pdf.PdfReader(file)\n",
    "    print(pdf_reader,\"\\n\")\n",
    "    print('length of pdf',len(pdf_reader.pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a489bde9-b86c-4e0f-9106-e70077470ab6",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pdf_data(pdf_path):\n",
    "    with open(pdf_path,\"rb\") as f:\n",
    "        reader = PdfReader(f)\n",
    "        results = []\n",
    "        for i in range(len(reader.pages)):\n",
    "            selected_page = reader.pages[i]\n",
    "            text = selected_page.extract_text()\n",
    "            results.append(text)\n",
    "        return ' '.join(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3a11f96-4d8f-4cca-8cfd-55c5583069d7",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "data =get_pdf_data(\"ProjectReport .pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1c47a62-f7c1-4cc1-868a-c26d5cdea924",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AUT OMA TIC THREA T DETECTION AND THEFT TRAPPING THROUGH VIDEO SUR VEILLANCE SYSTEM A PROJECT REPORT Submitted by CHANDRASEKAR CS (720818106006) JAYESH PT (720818106016) ANSON THOMAS (720818106702) In partial fulfillment for the award of the degree Of BACHELOR OF ENGINEERING IN ELECTRONICS AND COMMUNICA TION ENGINEERING HINDUSTHAN INSTITUTE OF TECHNOLOGY ANNA UNIVERSITY : CHENNAI 600 025 1 ANNA UNIVERSITY : CHENNAI 600 025 BONAFIDE CERTIFICATE Certified that this project report entitled “AUTOMATIC THREAT DETECTION AND THEFT TRAPPING THROUGH VIDEO SURVEILLANCE SYSTEM” is the bonafide work of “ CHANDRASEKAR C S, JAYESH P T , ANSON THOMAS ” who carried out the project work under my supervision  SIGNATURE SIGNATURE Dr  B  PAULCHAMY, M E ,Ph D , Mrs R PRIY ADHARSHINI, M E HEAD OF THE DEPARTMENT, SUPER VISOR, Professor & Head, Assistant Professor , Department of Electronics and Department of Electronics and Communication Engineering, Communication Engineering, Hindusthan Institute of Hindusthan Institute of Technology, Technology, Coimbatore  32  Coimbatore  32  Submitted for the University Project viva voice conducted on                                                                                          INTERNAL EXAMINER EXTERNAL EXAMINER 2 ACKNOWLEDGEMENT We express our sincere thanks to almighty god , the guiding light of our life for giving us the potential and courage to complete this project successfully  We would like to express our sincere thanks to the Chairman Sri T S R KANNAIYAN and Smt  SARASWATHI KHANNAIYAN of Hindusthan Educational and Charitable Trust for providing the facilities within the College  We express our gratitude to Dr  C NATARAJAN ,M E ,Ph D Principal  We take it as a privilege to express our profuse thanks for his encouragement and facilities provided to complete the project successfully  We owe our deep gratitude to, Dr  B PAULCHAMY, M E , Ph D  , Professor and Head of Electronics and communication Department, who took keen interest in our project work and guided us all along, till the completion of our project work by providing all the necessary information for developing a good system  We Profoundly indebted to our Supervisor Mrs R PRIYADHARSHINI,M E  , for her invaluable cordial support, valuable information and guidance, which helped us in completing the project through various stages  We are thankful to and fortunate enough to get constant encouragement, support and guidance from all Teaching staff of Electronics and communication Engineering which helped us in successfully completing our project work  Also, I would like to extend our sincere esteems to all staff in the laboratory for their timely support  We would like to thank our family and friends for supporting us throughout the years, financially, practically and with moral support to complete our project  3 ABSTRACT Close Circuit Television Camera (CCTV) has played a very important role in many surveillance and security systems  However, such a system requires continuous monitoring by humans and hence there is a possibility of failure because of boredom or fatigue  The requirements of continuous monitoring can be avoided using sensor systems which can alert the human on the occurrence of undesired events  Sensors only detect events and do not provide information about the threat  By analyzing the captured video, information about the threat and cause can be obtained very quickly and accurately in order to take mitigating actions  This paper reviews different approaches for detecting objects and its motion, tracking of object and activity consequences in order to prevent adverse uences  It also proposes methodology to improve the security of Nuclear Power Plants using existing approaches with appropriate modification  4 CONTENT SECTION NUMBER TOPIC PAGE NUMBER 1 Introduction 11 1 1 Project Overview 11 1 2 Structure of the paper 12 2 Literature Survey 13 2 1 Introduction 13 2 2 Existing Methodology 13 2 2 Summery 15 3 Methodologies 16 3 1 Introduction 16 3 2 Limitation 16 3 3 Proposed System 16 3 4 Advantages 17 3 5 Block Diagram 18 3 6 Circuit Diagram 19 3 7 Flow Chart 20 3 8 Algorithm 21 4 Hardware Description 22 4 1 Raspberry Pi 22 4 2 Specifications 23 4 3 GPIO pins 24 4 4 Pi Camera 26 4 5 Specifications 26 4 6 Relay 27 4 7 Relay : Specifications 27 4 8 Buzzer 29 5 4 9 Buzzer: Specifications 29 4 10 LED 30 5 Software Setup 32 5 1 Python 32 5 2 Features of Python 32 5 3 Computer Vision 33 5 4 Open CV 35 5 5 Application of OpenCv 35 5 6 OpenCv functionality 36 5 7 Image Processing 36 5 8 Digital Image 37 5 9 Flask 38 5 10 API 38 5 11 Android Java 40 5 12 Android SDK 40 5 13 Components of Android SDK 41 5 14 Android XML 43 5 15 Volley 44 5 16 Volley : Features 44 5 17 Advantages of Volly 45 5 18 Webview 45 5 19 Recyclerview 45 5 20 Heroku 45 5 21 Google Firebase 46 5 22 Features 47 5 23 Real time database 47 5 24 Cloud Storage 49 6 5 25 Cloud Messaging 49 6 Working principles 51 6 1 Introduction 51 6 2 Workflow 52 6 3 Motion Detection 52 6 4 Motion Detection Algorithm 53 6 5 Background Subtraction 55 6 6 Gaussian Blur 58 6 7 Trapping The Trespassers 58 6 8 Alerts 59 7 Results and discussions 60 7 1 Introduction 60 7 2 Camera feed 61 7 3 Mobile App 62 7 4 Alert 63 8 Conclusion and future 65 8 1 Conclusion 65 8 2 Future Enhancement 65 7 LIST OF FIGURES SECTION TITLE PAGE NUMBER 1 1 Burglary Rate 11 3 1 CCTV 16 3 2 Block Diagram 18 3 3 Circuit Diagram 19 3 4 Flow Chart 20 4 1 Raspberry Pi 22 4 2 GPIO Pin 24 4 3 Pi Camera 27 4 4 Relay 28 4 5 Relay Schematic 29 4 6 Buzzer 30 4 7 LED 31 5 1 Computer Vision 35 5 2 Image Processing 37 5 3 API 39 5 4 SDK Platform 43 5 5 Android XML 44 5 6 Heroku 46 5 7 Firebase 47 5 8 Real time database 48 5 9 Cloud Storage 49 5 10 Cloud Messaging 50 8 6 1 Motion Tracking 53 6 2 Motion Detection 55 6 3 Background subtraction 56 6 4 Gaussian Function 58 7 1 Camera Test 1 60 7 2 Camera Test 2 61 7 3 App UI 1 62 7 4 App Notification and alert 63 9 LIST OF ABBREVIATIONS ABBREVIATION EXPANSION API Application Programming Interface GCP Google Cloud Platform SaAS Software As A Service AWS Amazon Web Service NC Normally Close NO Normally Open CMOS Complementary Metal Oxide Semiconductor LED Light Emitting Diode IC Integrated Circuit PWM Pulse Width Modulation UAR T Universal Asynchronous Receiver/T ransmitter PCC Power Control Center PCB Printed Circuit Board 10 CHAPTER 1 INTRODUCTION 1 1 PROJECT OVERVIEW One of the most important concerns in the modern day world, be it for homes or businesses is security  An estimated 2,000,000 burglaries are reported each year in the United States out of which 66% are attributed to break ins  An increased number of people in the workforce limits the amount of time that people spend at home leaving home security vulnerable  In addition to break ins, the rise of online shopping led to skyrocketed porch pirating in recent times  An estimated 25 9 million Americans reported porch pirating in 2017 which was up from 25 3 million in 2017  This paper focuses on addressing home and business security concerns by providing a motion detection solution using Raspberry Pi and Camera  Automated video surveillance systems have emerged as an important research topic in the computer vision community  The growth in this area is being driven by the increased availability of inexpensive computing power and image sensors, as well as by the inefficiency of manual surveillance and monitoring system Applications such as event detection, human action recognition, and semantic indexing of video are being developed in order to partially or fully automate the task of surveillance  Figure 1 1 : Burglary Rate 11  The Raspberry Pi is a small sized computer (almost the size of a credit card) that has the ability to plug into a computer monitor or any other display and can be connected to a keyboard and mouse for operation  It has an operating system called Raspbian OS and can be a very handy system to run applications in programming languages like Scratch and Python  Although small, the Raspberry Pi is a system that approximates a desktop or a laptop in terms of functionality  The Raspberry Pi can also connect to the internet  Mundane activities performed on a desktop/ laptop such as browsing the internet, spreadsheet creation, word processing and gaming can all be performed on the Raspberry Pi  A smart surveillance security camera system can have many benefits for industrial site, including (Reduced theft, protect employees, building security, remote monitoring of facility from Smartphone or tablet, deter trespassers from attempting to gain access to facility)  The problematic for surveillance system or CCTV camera is costly because of the use many expensive components like computer, camera, cable, also we need a hard disk with higher capacity for save video It reserves too much space for continues recording and require manpower to detect the unauthorized Activity  But compared to Raspberry Pi, the system is much cheaper with high resolution and low power consumption features  Which means it can solve many of the issues of cost that may discourage consumers from investing in remote surveillance technology  1 2 STRUCTURE OF THE PROJECT Chapter 2 – Deals with Literature Survey Chapter 3 – Deals with Existing system Chapter 4 – Deals with Proposed Methodology Chapter 5  Deals with Results and Discussion Chapter 6– Deals with Conclusion 12 CHAPTER 2 LITERATURE SURVEY 2 1 INTRODUCTION Our focus is to design a system that will detect threats in time under different lighting conditions using camera and sensor networks  This paper reviews different approaches for detecting objects and its motion, tracking of object and activity analysis in order to prevent adverse consequences  The requirements of continuous monitoring can be avoided using sensor systems which can alert the human on the occurrence of undesired events  The system introduced by Khot Harish S, Gote Swati R, Khatal Sonali B, Pandarge Sangmesh introduces intelligent analysis of single person activity to enhance the security system in home and also enriches the current video surveillance systems through an automatic identification of abnormal behavior of the person  Smart Surveillance is the use of automatic video analytics to enhance effectiveness of surveillance systems  Smart video surveillance systems are capable of enhancing situational awareness across multiple scales of space and time  Moreover, there is a need to display which frame and which parts of the recording contain the uncommon activity which helps the quicker judgment of that unordinary action being unusual or suspicious  We intend to utilize different Deep Learning models (CNN and RNN) to identify and classify levels of high movement in the frame  From there, we can raise a detection alert for the situation of a threat, indicating the suspicious activities at an instance of time  2 2 EXTRACTING KNOWLEDGE FROM EXISTING METHODOLOGY ❖ Automatic Alert of Security Threat through Video Surveillance System Close Circuit Television Camera (CCTV) has played a very important role in many surveillance and security systems  However, such a system requires continuous monitoring by humans and hence there is a possibility of failure because of boredom or fatigue  The requirements of continuous monitoring can be avoided using sensor systems which can alert the human on the occurrence of undesired events  Sensors only detect events and do not provide information about the threat  Hence use of CCTV camera and sensor systems, independently or jointly, may not 13 be sufficient for timeliness detection of undesired events  When combined with humans and sensors, cameras can provide an immediate method to assess a scene of interest  Human efforts in monitoring can be greatly reduced by using activity analysis of video captured by CCTV  By analyzing the captured video, information about the threat and cause can be obtained very quickly and accurately in order to take mitigating actions  However, in the absence of light, the camera cannot detect such a threat  Hence, some hybrid techniques need to be implemented, which can work in different lighting conditions  So our focus is to design a system that will detect threats in time under different lighting conditions using camera and sensor networks  The system will be aided with smart, measureable, reliable and robust algorithms for motion detection, tracking and activity analyses  This paper reviews different approaches for detecting objects and its motion, tracking of object and activity analysis in order to prevent adverse consequences  It also proposes methodology to improve the security of Nuclear Power Plants using existing approaches with appropriate modification  ❖ Smart Video Surveillance Khot Harish S, Gote Swati R, Khatal Sonali B, Pandarge Sangmesh Video Surveillance has been used in many applications including elderly care and home nursing etc  Smart video surveillance systems are capable of enhancing situational awareness across multiple scales of space and time  It describes mobile based remote control and surveillance architecture  This project makes use of the Opencv library to capture camera images and detect intrusion using image comparison techniques  Once the comparison is done and an intrusion is found, it sends the streamed video from server to remote administrator over android phone  Admin can then take appropriate action and alert local security  Smart Surveillance is the use of automatic video analytics to enhance effectiveness of surveillance systems  This system introduces intelligent analysis of single person activity to enhance the security system in home and also enriches the current video surveillance systems through an automatic identification of abnormal behavior of the person  The relevant data is recorded and an alert is given to the user by sending MMS, SMS or mail  The user can view the particular video  This system maintains the security situation at home and this reduces the incidence of burglary cases and enhances social stability  14 ❖ Real Time Anomaly Recognition Through CCTV Using Neural Networks Nowadays, there has been a rise in the amount of disruptive and offensive activities that have been happening  Due to this, security has been given principal significance  Public places like shopping centers, avenues, banks, etc are increasingly being equipped with CCTVs to guarantee the security of individuals  Subsequently, this inconvenience is making a need to computerize this system with high accuracy  Since constant observation of these surveillance cameras by humans is a near impossible task  It requires workforces and their constant attention to judge if the captured activities are anomalous or suspicious  Hence, this drawback is creating a need to automate this process with high accuracy  Moreover, there is a need to display which frame and which parts of the recording contain the uncommon activity which helps the quicker judgment of that unordinary action being unusual or suspicious  Therefore, to reduce the wastage of time and labor, we are utilizing deep learning algorithms for Automating Threat Recognition Systems  Its goal is to automatically identify signs of aggression and violence in real time, which filters out irregularities from normal patterns  We intend to utilize different Deep Learning models (CNN and RNN) to identify and classify levels of high movement in the frame  From there, we can raise a detection alert for the situation of a threat, indicating the suspicious activities at an instance of time  2 3 SUMMARY The automated video surveillance system has risen as a significant research topic in the field of public security  A lot of work has been reported, addressing the movement recognition and tracking of an object  Artificial intelligence has also contributed a lot to reduce workload and increase the efficiency of surveillance  There have been numerous attempts to partially or completely automate this task with applications like Event detection, human activity recognition, and behavior analysis  Anomaly recognition is quite a challenging and time honored concern of Computer Vision   To recognize the violent or aggressive pattern from the recordings in real time surveillance applications  The system needs to perform multiple attempts  15 CHAPTER 3 METHODOLOGIES 3 1 INTRODUCTION A CCTV (closed circuit television) system allows the use of video cameras to monitor the interior and exterior of a property, transmitting the signal to a monitor or set of monitors  It keeps the video footage in any storage system like a hard disk  The system consumes more spaces in disk storage to save the video footage  It can monitor anything in its range  But Now many physical attacks towards surveillance systems will cause complete damage to the system   Figure 3 1 CCTV 3 2 LIMITATIONS ● Existing system cannot prevent any attack towards the surveillance system  ● Consume More disk space to store video footage 3 3 PROPOSED SYSTEM Considering the drawbacks of the existing system, to overcome these problems, the proposed system aims to ensure security of both surveillance and 16  surveillance systems by implementing a motion detection system, which can easily be controlled by users around the globe and the users can control it from sitting at one place  In this proposed system, users can easily track people present at that particular surroundings that will analyze their activities if the system finds anything suspicious it will take action accordingly The user has to set a few parameters in order to let the system know about their choices about the type of security they want  When a person is detected by the system, an image is sent to the user so that they can know all about the activities that are going on in the surroundings This system also helps in capturing the persons who are creating the undesirable activities and method of trapping such as, closing of doors when a trespasser enters, emergency messages and notifications, release of gas which causes numbness that will help in securing the environment  By using these techniques we can easily trap the trespassed person and catch them without any physical interaction  This system is not only secure but also it helps in finding the trespasser and can take immediate actions towards it, which makes it more unique then the present system  Technically speaking, this project is mainly implemented using a microcomputer called the raspberry pi along with this, a camera is also attached with the same  Looking onto the user’s application, there will be a start button, a stop button as well as an image button  The user can access the live feed of the camera attached which would help the user know about the real time instances As soon as the start button is clicked by the user,motion detection is activated accordingly  Whenever even a small motion is detected by the camera, real time images are sent to the cloud and sends a push notification as well as an alert music starts playing on the user’s mobile phone alerting the user about the movement in that particular area  Clicking upon the image button will let the user know about the incident  If any unwanted activities are tracked, trapping methods would be activated immediately  Hence this secured system helps in tracking down trespassers as well as taking immediate action against them  3 4 ADVANTAGES ● Prevention of theft can be easily done using this method without any physical damage  ● Detection of theft can be done efficiently using this technique  ● This system can be controlled anywhere and the prevention method can be executed easily  17 3 5 BLOCK DIAGRAM The Block diagram consists of a Raspberry Pi, Pi Cam, Relays and Sprayer  The Raspberry Pi is the brain of the system  Then a Pi Camera to capture video  Other peripheral components like Electric sprayer, Relays are connected to the Raspberry Pi GPIO  The entire system connected to the cloud via the internet  Figure 3 2 : Block Diagram 18  3 6 CIRCUIT DIAGRAM The Peripheral parts, Relay module pins Input 1(INT1) and Input 2(INT2) are connected to GPIO06 and GPIO13 of the Raspberry Pi GPIO  The VCC and GND also took from the Raspberry Pi itself  The LED indicator is connected to GPIO26 and Buzzer is connected to GPIO19  The Pi Cam is connected to an FFC pin  Figure 3 3 : Circuit Diagram 19  3 7 FLOW CHART Figure 3 4 : Flow chart 20  3 8 ALGORITHM 1  START 2  Initialize Peripheral devices and Camera 3  Check internet connection a  If not, repeat the step 3 4  Connect to API 5  Start video camera 6  Take first image as a reference and save into a variable 7  Read next frame 8  Compare with Next image 9  Check for motion a  If Motion, Proceed to next step b  Else, Repeat step 7 onwards 10  Send image to cloud 11  Turn on Relay, Buzzer and LED 12  Wait for 2 Second 13  Turn of Relay, buzzer and LED 14  Send Push notification to the user 15  Repeat the step from 7 onwards 16  STOP 21 CHAPTER 4 HARDWARE DESCRIPTION 4 1 RASPBERRY PI The Raspberry Pi is a low cost, credit card sized computer that plugs into a computer monitor or TV, and uses a standard keyboard and mouse  It’s capable of doing everything you’d expect a desktop computer to do, from browsing the internet and playing high definition video, to making spreadsheets, word processing, and playing games  The Raspberry Pi has the ability to interact with the outside world, and has been used in a wide array of digital maker projects  Figure 4 1 Raspberry Pi Raspberry Pi 4 Model B is the latest product in the popular Raspberry Pi range of computers  It offers ground breaking increases in processor speed, 22  multimedia performance, memory, and connectivity compared to the prior generation Raspberry Pi 3 Model B+, while retaining backwards compatibility and similar power consumption  For the end user, Raspberry Pi 4 Model B provides desktop performance comparable to entry level x86 PC systems  This product’s key features include a high performance 64 bit quad core processor, dual display support at resolutions up to 4K via a pair of micro HDMI ports, hardware video decode at up to 4Kp60, up to 4GB of RAM, dual band 2 4/5 0 GHz wireless LAN, Bluetooth 5 0, Gigabit Ethernet, USB 3 0, and PoE capability (via a separate PoE HAT add on)  The dual band wireless LAN and Bluetooth have modular compliance certification, allowing the board to be designed into end products with significantly reduced compliance testing, improving both cost and time to market  4 2 SPECIFICATIONS ● Broadcom BCM2711, Quad core Cortex A72 (ARM v8) 64 bit SoC @ 1 5GHz ● 1GB, 2GB or 4GB LPDDR4 2400 SDRAM (depending on model) ● 2 4 GHz and 5 0 GHz IEEE 802 11ac wireless, Bluetooth 5 0, BLE ● Gigabit Ethernet ● 2 USB 3 0 ports; 2 USB 2 0 ports  ● Raspberry Pi standard 40 pin GPIO header (fully backwards compatible with previous boards) ● 2 × micro HDMI ports (up to 4kp60 supported) ● 2 lane MIPI DSI display port ● 2 lane MIPI CSI camera port ● 4 pole stereo audio and composite video port ● H 265 (4kp60 decode), H264 (1080p60 decode, 1080p30 encode) ● OpenGL ES 3 0 graphics ● Micro SD card slot for loading operating system and data storage ● 5V DC via USB C connector (minimum 3A*) ● 5V DC via GPIO header (minimum 3A*) ● Power over Ethernet (PoE) enabled (requires separate PoE HAT) ● Operating temperature: 0 – 50 degrees C ambient 23 4 3 GPIO PINS The GPIO is the most basic, yet accessible aspect of the Raspberry Pi  GPIO pins are digital which means they can have two states, off or on  They can have a direction to receive or send current (input, output respectively) and we can control the state and direction of the pins using programming languages such as Python, JavaScript, node RED etc  The operating voltage of the GPIO pins is 3 3v with a maximum current draw of 16mA  This means that we can safely power one or two LEDs (Light Emitting Diodes) from a single GPIO pin, via a resistor  But for anything requiring more current, a DC motor for example, we will need to use external components to ensure that we do not damage the GPIO  Figure 4 2 : Rpi GPIO Pinout Controlling a GPIO pin with Python is accomplished by first importing a library of pre written code  The most common library is RPi GPIO (https://pypi org/project/RPi GPIO/) and it has been used to create thousands of projects since the early days of the Raspberry Pi  In more recent times a new library called GPIO Zero (https://pypi org/project/gpiozero/)has been introduced, offering 24  an easier entry for those new to Python and basic electronics  Both of these libraries come pre installed with the Raspbian operating system  GPIO pins have multiple names; the first most obvious reference is their “physical” location on the GPIO  Starting at the top left of the GPIO, and by that we mean the pin nearest to where the micro SD card is inserted, we have physical pin 1 which provides 3v3 power  To the right of that pin is physical pin 2 which provides 5v power  The pin numbers then increase as we move down each column, with pin 1 going to pin 3, 5,7 etc until we reach pin 39  You will quickly see that each pin from 1 to 39 in this column follows an odd number sequence  And for the column starting with pin 2 it will go 4,6,8 etc until it reaches 40  Following an even number sequence  Physical pin numbering is the most basic way to locate a pin, but many of the tutorials written for the Raspberry Pi follow a different numbering sequence  Broadcom (BCM) pin numbering (aka GPIO pin numbering) seems to be chaotic to the average user  With GPIO17, 22 and 27 following on from each other with little thought to logical numbering  The BCM pin mapping refers to the GPIO pins that have been directly connected to the System on a Chip (SoC) of the Raspberry Pi  In essence we have direct links to the brain of our Pi to connect sensors and components for use in our projects  You will see the majority of Raspberry Pi tutorials using this reference and that is because it is the officially supported pin numbering scheme from the Raspberry Pi Foundation  So it is best practice to start using and learning the BCM pin numbering scheme as it will become second nature to you over time  Also note that BCM and GPIO pin numbering refer to the same scheme  So for example GPIO17 is the same as BCM17  Certain GPIO pins also have alternate functions that allow them to interface with different kinds of devices that use the I2C, SPI or UART protocols  For example GPIO3 and GPIO 4 are also SDA and SCL I2C pins used to connect devices using the I2C protocol  To use these pins with these protocols we need to enable the interfaces using the Raspberry Pi Configuration application found in the Raspbian OS, Preferences menu  25 4 4 PI CAMERA This Raspberry Pi Camera Module is a custom designed add on for Raspberry Pi  It attaches to Raspberry Pi by way of one of the two small sockets on the board upper surface  This interface uses the dedicated CSI interface, which was designed especially for interfacing to cameras  The CSI bus is capable of extremely high data rates, and it exclusively carries pixel data  The board itself is tiny, at around 25mm x 23mm x 8mm  It also weighs just over 3g, making it perfect for mobile or other applications where size and weight are important  It connects to Raspberry Pi by way of a short flexible ribbon cable  The camera connects to the BCM2835 processor on the Pi via the CSI bus, a higher bandwidth link which carries pixel data from the camera back to the processor  This bus travels along the ribbon cable that attaches the camera board to the Pi  The sensor itself has a native resolution of 5 megapixels and has a fixed focus lens onboard  In terms of still images, the camera is capable of 2592 x 1944 pixel static images, and also supports 1080p30, 720p60 and 640x480p60/90 video  4 5 PI CAMERA SPECIFICATION ● Fully Compatible with Both the Model A, Model B and Model B+ Raspberry Pi ● 5MP Omnivision 5647 Camera Module Still ● Picture Resolution: 2592 x 1944 ● Video: Supports 1080p @ 30fps, 720p @ 60fps and 640x480p 60/90 Recording ● 15 pin MIPI Camera ● Serial Interface   Plugs Directly into the Raspberry Pi ● Board Size: 20 x 25 x 9mm ● Weight 3g 26 Figure 4 3 Raspberry Pi Camera 4 6 RELAY MODULE A relay is an electromagnetic switch operated by a relatively small current that can control much larger current  Initially the first circuit is switched off and no current flows through it until something (either a sensor or switch closing) turns it on  The second circuit is also switched off  When a small current flows through the first circuit, it activates the electromagnet, which generates a magnetic field all around it  The energized electromagnet attracts contact in the second circuit toward it, closing the switch and allowing a much bigger current to flow through the second circuit  When the current stops flowing, the contact goes back up to its original position, switching the second circuit off again  This module is designed for switching two high powered devices from your Arduino  It has two relays rated up to 10A per channel at 250VAC or 30VDC  There are two LEDs on the relay module indicating the position of the relay  Whenever a relay is activated, the respective LED will light up  One of the best things about 27  these modules is that they come with two Optocoupler ICs which provide good isolation between relay and Arduino  Figure 4 4 Relay Module 4 7 FEATURES ● Good for safe control of higher amperage circuits  ● In power systems, the lower current can control the higher one  ● 2 channel high voltage system output, meeting the needs of dual channel control  ● Brand new and high quality  ● Standard interface that can be controlled directly by microcontroller (Arduino , 8051, AVR, PIC, DSP, ARM)] ● Wide range of controllable voltages  ● Being able to control high load current, which can reach 250V, 10A or 125V, 15A With a normally open (NO) contact and a normally closed (NC) contact  ● Around the board with 4 mounting holes, easy installation and fixing It has a common end, a beginning, a closed end 28  Figure 4 5 Relay Schematic 4 8 BUZZER Buzzer is an active buzzer, which basically means that it will buzz at a predefined frequency (2300 ±300 Hz) on its own even when you just apply steady DC power  Advantage to an active buzzer is that you can still produce a sound from the buzzer connected to a microcontroller, such as an Arduino, by just driving a standard high output on the connected pin  The benefits of this are that you don\\'t need to use processing power, hardware timers, or additional code to produce sound  4 9 BUZZER SPECIFICATION ● Rated Voltage   5 V ● Operating Voltage 4~8 V ● Max Rated Current   ≤32 mA ● Min  Sound Output at 10cm   85 dB ● Resonant Frequency   2300 ±300 Hz ● Operating Temperature    20°C to 45°C ● Dimensions (Excluding Pins) Height 9 16 mm, Diameter 11 78 mm ● Weight   1 6 g 29  Figure 4 6 : Buzzer 4 10 LED A light emitting diode (LED) is a semiconductor light source that emits light when current flows through it  Electrons in the semiconductor recombine with electron holes, releasing energy in the form of photons  The color of the light (corresponding to the energy of the photons) is determined by the energy required for electrons to cross the band gap of the semiconductor  White light is obtained by using multiple semiconductors or a layer of light emitting phosphor on the semiconductor device  Appearing as practical electronic components in 1962, the earliest LEDs emitted low intensity infrared (IR) light  Infrared LEDs are used in remote control circuits, such as those used with a wide variety of consumer electronics  The first visible light LEDs were of low intensity and limited to red  Early LEDs were often used as indicator lamps, replacing small incandescent bulbs, and in seven segment displays  Recent developments have produced LEDs available in visible, ultraviolet (UV), and infrared wavelengths, with high, low, or intermediate light output, for instance white LEDs suitable for room and outdoor area lighting  LEDs have also given rise to new types of displays and sensors, while their high switching rates are useful in advanced communications technology with applications as diverse as aviation lighting, fairy lights, automotive headlamps, advertising, general lighting, traffic signals, camera flashes, lighted wallpaper, horticultural grow lights, and medical devices  LEDs have many advantages over incandescent light sources, including lower power consumption, longer lifetime, 30  improved physical robustness, smaller size, and faster switching  In exchange for these generally favorable attributes, disadvantages of LEDs include electrical limitations to low voltage and generally to DC (not AC) power, inability to provide steady illumination from a pulsing DC or an AC electrical supply source, and lesser maximum operating temperature and storage temperature  In contrast to LEDs, incandescent lamps can be made to intrinsically run at virtually any supply voltage, can utilize either AC or DC current interchangeably, and will provide steady illumination when powered by AC or pulsing DC even at a frequency as low as 50 Hz  LEDs usually need electronic support components to function, while an incandescent bulb can and usually does operate directly from an unregulated DC or AC power source  Figure 4 7 : LED 31  CHAPTER 5 SOFTWARE SETUP 5 1 PYTHON Python is an easy to learn, powerful programming language  It has efficient high level data structures and a simple but effective approach to object oriented programming  Python’s elegant syntax and dynamic typing, together with its interpreted nature, make it an ideal language for scripting and rapid application development in many areas on most platforms  The Python interpreter and the extensive standard library are freely available in source or binary form for all major platforms from the Python web site, https://www python org/, and may be freely distributed  The same site also contains distributions of and pointers to many free third party Python modules, programs and tools, and additional documentation  The Python interpreter is easily extended with new functions and data types implemented in C or C++ (or other languages callable from C)  Python is also suitable as an extension language for customizable applications  5 2 FEATURES OF PYTHON There are many features in Python, some of which are discussed below – ● Easy to code: Python is a high level programming language  Python is very easy to learn the language as compared to other languages like C, C#, Javascript, Java, etc  It is very easy to code in python language and anybody can learn python basics in a few hours or days  It is also a developer friendly language  ● Free and Open Source: Python language is freely available at the official website and you can download it from the given download link below click on the Download Python keyword  Download Python Since it is open source, this means that source code is also available to the public  So you can download it, use it as well as share it  ● Object Oriented Language: One of the key features of python is Object Oriented programming  Python supports object oriented language and concepts of classes, object encapsulation, etc  32 ● GUI Programming Support: Graphical User interfaces can be made using a module such as PyQt5, PyQt4, wxPython, or Tk in python  PyQt5 is the most popular option for creating graphical apps with Python  ● High Level Language: Python is a high level language  When we write programs in python, we do not need to remember the system architecture, nor do we need to manage the memory  ● Extensible feature: Python is an Extensible language  We can write some Python code into C or C++ language and also we can compile that code in C/C++ language  ● Python is Portable language: Python language is also a portable language  For example, if we have python code for windows and if we want to run this code on other platforms such as Linux, Unix, and Mac then we do not need to change it, we can run this code on any platform  ● Python is an Integrated language: Python is also an Integrated language because we can easily integrate python with other languages like c, c++, etc  ● Interpreted Language: Python is an Interpreted Language because Python code is executed line by line at a time  Unlike other languages C, C++, Java, etc  there is no need to compile python code; this makes it easier to debug our code  The source code of python is converted into an immediate form called bytecode  ● Large Standard Library Python has a large standard library which provides a rich set of modules and functions so you do not have to write your own code for every single thing  There are many libraries present in python such as regular expressions, unit testing, web browsers, etc  ● Dynamically Typed Language: Python is a dynamically typed language  That means the type (for example  int, double, long, etc ) for a variable is decided at run time not in advance because of this feature we don’t need to specify the type of variable  5 3 COMPUTER VISION Computer vision is a field of artificial intelligence (AI) that enables computers and systems to derive meaningful information from digital images, videos and other visual inputs — and take actions or make recommendations based on that information  If AI enables computers to think, computer vision enables them to see, observe and understand  Computer vision works much the same as human vision, except humans have a head start  Human sight has the advantage of lifetimes of context to train how to tell objects apart, how far 33 away they are, whether they are moving and whether there is something wrong in an image  Computer vision trains machines to perform these functions, but it has to do it in much less time with cameras, data and algorithms rather than retinas, optic nerves and a visual cortex  Because a system trained to inspect products or watch a production asset can analyze thousands of products or processes a minute, noticing imperceptible defects or issues, it can quickly surpass human capabilities  Computer vision needs lots of data  It runs analyses of data over and over until it discerns distinctions and ultimately recognizes images  For example, to train a computer to recognize automobile tires, it needs to be fed vast quantities of tire images and tire related items to learn the differences and recognize a tire, especially one with no defects  Two essential technologies are used to accomplish this: a type of machine learning called deep learning and a convolutional neural network (CNN)  Machine learning uses algorithmic models that enable a computer to teach itself about the context of visual data  If enough data is fed through the model, the computer will “look” at the data and teach itself to tell one image from another   Algorithms enable the machine to learn by itself, rather than someone programming it to recognize an image  A CNN helps a machine learning or deep learning model “look” by breaking images down into pixels that are given tags or labels  It uses the labels to perform convolutions (a mathematical operation on two functions to produce a third function) and makes predictions about what it is “seeing ” The neural network runs convolutions and checks the accuracy of its predictions in a series of iterations until the predictions start to come true  It is then recognizing or seeing images in a way similar to humans  Much like a human making out an image at a distance, a CNN first discerns hard edges and simple shapes, then fills in information as it runs iterations of its predictions  A CNN is used to understand single images  A recurrent neural network (RNN) is used in a similar way for video applications to help computers understand how pictures in a series of frames are related to one another   34 Figure 5 1 Computer Vision 5 4 OPENCV OpenCV is a huge open source library for computer vision, machine learning, and image processing  OpenCV supports a wide variety of programming languages like Python, C++, Java, etc  It can process images and videos to identify objects, faces, or even the handwriting of a human  When it is integrated with various libraries, such as Numpy which is a highly optimized library for numerical operations, then the number of weapons increases in your Arsenal i e whatever operations one can do in Numpy can be combined with OpenCV  5 5 APPLICATION OF OPENCV There are lots of applications which are solved using OpenCV, some of them are listed below ● Face recognition ● Automated inspection and surveillance ● Number of people – count (foot traffic in a mall, etc) ● Vehicle counting on highways along with their speeds ● Interactive art installations ● Anomaly (defect) detection in the manufacturing process (the odd defective products) 35  ● Street view image stitching ● Video/image search and retrieval ● Robot and driver less car navigation and control ● Object recognition ● Medical image analysis ● Movies – 3D structure from motion ● TV Channels advertisement recognition 5 6 OPENCV FUNCTIONALITY ● Image/video I/O, processing, display (core, imgproc, highgui) ● Object/feature detection (objdetect, features2d, nonfree) ● Geometry based monocular or stereo computer vision (calib3d, stitching, videostab) ● Computational photography (photo, video, superres) ● Machine learning & clustering (ml, flann) ● CUDA acceleration (gpu) 5 7 IMAGE PROCESSING Image processing is the process of transforming an image into a digital form and performing certain operations to get some useful information from it  The image processing system usually treats all images as 2D signals when applying certain predetermined signal processing methods  There are five main types of image processing: ● Visualization   Find objects that are not visible in the image ● Recognition   Distinguish or detect objects in the image ● Sharpening and restoration   Create an enhanced image from the original image ● Pattern recognition   Measure the various patterns around the objects in the image ● Retrieval   Browse and search images from a large database of digital images that are similar to the original image 36 Figure 5 2 Image processing 5 8 DIGITAL IMAGE An image may be defined as a two dimensional function f(x, y), where x and y are spatial(plane) coordinates, and the amplitude of any pair of coordinates (x, y) is called the intensity or gray level of the image at that point  In another word An image is nothing more than a two dimensional matrix (3 D in case of coloured images) which is defined by the mathematical function f(x, y) at any point is giving the pixel value at that point of an image, the pixel value describes how bright that pixel is, and what color it should be  Image processing is basically signal processing in which input is an image and output is image or characteristics according to requirements associated with that image  Image processing basically includes the following three steps: Importing the image Analyzing and manipulating the image Output in which result can be altered image or report that is based on image analysis  37  5 9 FLASK Flask is a web application framework written in Python  Armin Ronacher, who leads an international group of Python enthusiasts named Pocco, develops it  Flask is based on the Werkzeug WSGI toolkit and Jinja2 template engine  Both are Pocco projects  Web Server Gateway Interface (WSGI) has been adopted as a standard for Python web application development  WSGI is a specification for a universal interface between the web server and the web applications  It is a WSGI toolkit, which implements requests, response objects, and other utility functions  This enables building a web framework on top of it  The Flask framework uses Werkzeug as one of its bases  Jinja2 is a popular templating engine for Python  A web templating system combines a template with a certain data source to render dynamic web pages  Flask is often referred to as a micro framework  It aims to keep the core of an application simple yet extensible  Flask does not have a built in abstraction layer for database handling, nor does it have form validation support  Instead, Flask supports the extensions to add such functionality to the application  Some of the popular Flask extensions are discussed later in the tutorial  5 10 API An application programming interface, or API, enables companies to open up their applications’ data and functionality to external third party developers, business partners, and internal departments within their companies  This allows services and products to communicate with each other and leverage each other’s data and functionality through a documented interface  Developers don\\'t need to know how an API is implemented; they simply use the interface to communicate with other products and services  API use has surged over the past decade, to the degree that many of the most popular web applications today would not be possible without APIs  An API is a set of defined rules that explain how computers or applications communicate with one another  APIs sit between an application and the web server, acting as an intermediary layer that processes data transfer between systems  Here’s how an API works: 1  A client application initiates an API call to retrieve information—also known as a r e q u e s t   This request is processed from an application to the web server 38 via the API’s Uniform Resource Identifier (URI) and includes a request verb, headers, and sometimes, a request body  2  After receiving a valid request, the API makes a call to the external program or web server  3  The server sends a r e s p o n s e to the API with the requested information  4  The API transfers the data to the initial requesting application  While the data transfer will differ depending on the web service being used, this process of requests and response all happens through an API  Whereas a user interface is designed for use by humans, APIs are designed for use by a computer or application  Figure 5 3 API APIs offer security by design because their position as middleman facilitates the abstraction of functionality between two systems—the API endpoint decouples the consuming application from the infrastructure providing the service  API calls usually include authorization credentials to reduce the risk of attacks on the server, and an API gateway can limit access to minimize security threats  Also, during the exchange, HTTP headers, cookies, or query string parameters provide additional security layers to the data  For example, consider an API offered by a payment processing service  Customers can enter their card details on the frontend of an application for an ecommerce store  The payment processor doesn’t require access to the user’s bank account; the API creates a unique token for this transaction and includes it in the API call to the server  This ensures a higher level of security against potential hacking threats  39  5 11 ANDROID JAVA Android is an open source and Linux based operating system for mobile devices such as smartphones and tablet computers  Android was developed by the Open Handset Alliance, led by Google, and other companies  This tutorial will teach you basic Android programming and will also take you through some advanced concepts related to Android application development  Android applications are developed using the Java language  As of now, that’s really your only option for native applications  Java is a very popular programming language developed by Sun Microsystems (now owned by Oracle)  Developed long after C and C++, Java incorporates many of the powerful features of those powerful languages while addressing some of their drawbacks  Still, programming languages are only as powerful as their libraries  These libraries exist to help developers build applications  Some of Java\\'s important core features are: ● It’s easy to learn and understand  ● It\\'s designed to be platform independent and secure, using virtual machines ● Its object oriented Android relies heavily on these Java fundamentals  The Android SDK includes many standard Java libraries (data structure libraries, math libraries, graphics libraries, networking libraries and everything else you could want) as well as special  Android libraries that will help you develop awesome Android applications  5 12 ANDROID SDK Android SDK is a collection of libraries and Software Development tools that are essential for Developing Android Applications  Whenever Google releases a new version or update of Android Software, a corresponding SDK also releases with it  In the updated or new version of SDK, some more features are included which are not present in the previous version  Android SDK consists of some tools which are very essential for the development of Android Application  These tools provide a smooth flow of the development process from developing and debugging  Android SDK is compatible with all operating systems such as Windows, Linux, macOS, etc  40 5 13 COMPONENTS OF ANDROID SDK Android SDK Components play a major role in the Development of Android applications  Below are the important components: 1  Android SDK Tools Android SDK tool is an important component of Android SDK  It consists of a complete set of development and debugging tools  Below are the SDK developer tools: ● Android SDK Build tool  ● Android Emulator  ● Android SDK Platform tools  ● Android SDK Tools  2  Android SDK Build Tools Android SDK build tools are used for building actual binaries of Android Apps  The main functions of Android SDK Build tools are built, debug, run and test Android applications  The latest version of the Android SDK Build tool is 30 0 3  While downloading or updating Android in our System, one must ensure that its latest version is downloaded in SDK Components  3  Android Emulator An Android Emulator is a device that simulates an Android device on your system  Suppose we want to run our android application that we code  One option is that we will run this on our Android Mobile by Enabling USB Debugging on our mobile  Another option is using Android Emulator  In Android Emulator the virtual android device is shown on our system on which we run the Android application that we code  Thus, it simply means that without needing any physical device Android SDK component “Android Emulator” provides a virtual device on the System where we run our Application  The emulator’s come with the configuration for Various android phones, tablets, Wear OS, and Android TV devices  41 In Android Virtual Emulator all functions that are feasible on real Android mobile is works on virtual Device like: ● Phone calls, text messages  ● Stimulate different network speeds  ● Specify the location of a device access on google play store and lot’s more  But there is one disadvantage of this emulator  It is very slow when System’s PC has less RAM  It works fine when a maximum GB of RAM is present on our device  4  Android SDK Platform tools Android SDK Platform tools is helpful while working on a Project and they will show the error messages at the same time  It is specifically used for testing  It includes: Android Debug Bridge (ADB), is a command line tool that helps to communicate with the device  It allows us to perform actions such as Installing apps, Debugging apps etc  Fastboot allows you to flash a device with a new system image  Systrace tools help to collect and inspect timing information  It is very crucial for App Debugging  5  Android SDK Tools Android SDK tool is a component of SDK tool  It consists of a set of tools and other Utilities which are crucial for the development of Android Application  It contains the complete set of Debugging and Development tools for android  6  SDK Platforms For each Android Software, one SDK platform is available as shown below: 42 Figure 5 4 SDK platform Like in this Android 11 0(R) is installed  These are numbered according to the android version  The new version of the SDK platform has more features and is more compatible but the old version is less compatible with fewer features  Like in Android 11 0(R) are more compatible and have more features but the below versions like Android 10 0(Q), Android4 4(KitKat) have less features and are less compatible  7  SDK Update Sites In SDK Update Sites, some sites are embedded in it which will check for Android SDK Updates Tools  In this, one must ensure we don’t unclick the button below because these are checked by default which will check for updates if we unclic it then it doesn’t check updates for those  5 14 ANDROID XML XML stands for Extensible Markup Language  XML is a markup language much like HTML used to describe data  It is derived from Standard Generalized Markup Language(SMGL)  Basically, the XML tags are not predefined in XML  We need to implement and define the tags in XML  XML tags define the data and are 43  used to store and organize data  It’s easily scalable and simple to develop  In Android, the XML is used to implement UI related data, and it’s a lightweight markup language that doesn’t make layout heavy  XML only contains tags, while implementing they need to be just invoked  Figure 5 5 Android XML 5 15 VOLLEY Volley is an HTTP library that makes networking very easy and fast, for Android apps  It was developed by Google and introduced during Google I/O 2013  It was developed because there is an absence in Android SDK, of a networking class capable of working without interfering with the user experience  Although Volley is a part of the Android Open Source Project(AOSP), Google announced in January 2017 that Volley will move to a standalone library  It manages the processing and caching of network requests and it saves developers valuable time from writing the same network call/cache code again and again  Volley is not suitable for large download or streaming operations since Volley holds all responses in memory during parsing  5 16 FEATURES OF VOLLEY ● Request queuing and prioritization ● Effective request cache and memory management ● Extensibility and customization of the library to our needs ● Canceling the requests 44  5 17 ADVANTAGES OF USING VOLLEY ● All the tasks that need to be done with Networking in Android, can be done with the help of Volley  ● Automatic scheduling of network requests  ● Catching ● Multiple concurrent network connections  ● Canceling request API  ● Request prioritization  ● Volley provides debugging and tracing tools  ● While dealing with high resolution compressed images, Volley is the only solution here that works well  5 18 WEBVIEWS WebView objects allow to display web content as part of activity layout, but lack some of the features of fully developed browsers  A WebView is useful when we need increased control over the UI and advanced configuration options that will allow you to embed web pages in a specially designed environment for your app  5 19 RECYCLERVIEW RecyclerView makes it easy to efficiently display large sets of data  You supply the data and define how each item looks, and the RecyclerView library dynamically creates the elements when they\\'re needed  As the name implies, RecyclerView recycles those individual elements  When an item scrolls off the screen, RecyclerView doesn\\'t destroy its view  Instead, RecyclerView reuses the view for new items that have scrolled on screen  This reuse vastly improves performance, improving your app\\'s responsiveness and reducing power consumption  5 20 HEROKU Heroku is a cloud service platform whose popularity has grown in recent years  Heroku is so easy to use that it’s a top choice for many development projects  45 With a special focus on supporting customer focused apps, it enables simple application development and deployment  Since the Heroku platform manages hardware and servers, businesses that use Heroku are able to focus on perfecting their apps  And not the infrastructure that supports them  More time goes towards ensuring that users receive the highest quality experiences as possible  Heroku officially supports these languages  However, it does not limit itself to these languages  ● Java ● Ruby ● PHP ● Node js ● Python ● Scala ● Clojure You can also run any language that runs on Linux or Heroku via a third party build pack  Figure 5 6 : Heroku 5 21 GOOGLE FIREBASE Firebase is a development platform for mobile and web apps  With Firebase, you can quickly build high quality apps, grow an engaged user base, and earn more money  The platform includes several tightly integrated features that you can mix and match, including analytics, a mobile first backend, and app growth and monetization tools to help maximize app success  46  Figure 5 7 : Firebase 5 22 KEY FEATURES 1  Authentication:  It supports authentication using passwords, phone numbers, Google, Facebook, Twitter, and more  The Firebase Authentication (SDK) can be used to manually integrate one or more sign in methods into an app  2  Realtime database:  Data is synced across all clients in real time and remains available even when an app goes offline  3  Firebase Hosting provides fast hosting for a web app content is cached into content delivery networks worldwide  4  Test lab:  The application is tested on virtual and physical devices located in Google’s data centers  5  Notifications:  Notifications can be sent with firebase with no additional coding  5 23 REALTIME DATABASE The Firebase Realtime Database is a cloud hosted database in which data is stored as JSON  The data is synchronized in real time to every connected client  All of our clients share one Realtime Database instance and automatically receive 47  updates with the newest data, when we build cross platform applications with our iOS, and JavaScript SDKs  The Firebase Realtime Database is a NoSQL database from which we can store and sync the data between our users in real time  It is a big JSON object which the developers can manage in real time  By using a single API, the Firebase database provides the application with the current value of the data and updates to that data  Real time syncing makes it easy for our users to access their data from any device, be it web or mobile  The Realtime database helps our users collaborate with one another  It ships with mobile and web SDKs, which allow us to build our app without the need for servers  When our users go offline, the Real time Database SDKs use local cache on the device for serving and storing changes  The local data is automatically synchronized, when the device comes online  Figure 5 8 : Real Time Database 48  5 24 CLOUD STORAGE Cloud Storage for Firebase is a powerful, simple, and cost effective object storage service built for Google scale  The Firebase SDKs for Cloud Storage add Google security to file uploads and downloads for your Firebase apps, regardless of network quality  You can use our SDKs to store images, audio, video, or other user generated content  On the server, you can use Google Cloud Storage APIs to access the same files  Firebase Cloud Storage is capable of performing the following things: ● Robust Operations :  Reliability is one of the biggest advantages of the Cloud Firestore  Firebase SDKs perform uploads and downloads regardless of network quality  Downloads and uploads both are robust  Robust means from where it stopped, will restart from there, and save the user time and bandwidth  ● Strong security:  For providing simple and intuitive authentication to the developer, Firebase SDKs for Cloud Storage integrate with Firebase Authentication  For allowing access based on filename, size, content type, and other metadata, we can use declarative security models  ● High Scalability:  Cloud Storage is built for the Exabyte scale when our app goes viral  Easily grow from prototype to production using the same structure that powers Spotify and Google Photos  Figure 5 9 : Cloud Storage 49  5 25 CLOUD MESSAGING Firebase Cloud Messaging (FCM) is a cross platform messaging solution that lets you reliably send messages at no cost  Using FCM, you can notify a client app that new email or other data is available to sync  You can send notification messages to drive user re engagement and retention  For use cases such as instant messaging, a message can transfer a payload of up to 4000 bytes to a client app  Using deprecated Google Cloud Messaging APIs  FCM inherits the core infrastructure of GCM, however, it simplifies the development of the client side  GCM and FCM offer encryption, push notification and messaging, native Android and iOS SDK support  Both require a third party entity between the client application and the trusted environment which may create delays in the communication path between the mobile terminal and application server  FCM supports server protocols HTTP and XMPP which are identical to GCM protocols  Developers are not required to write individual registrations or subscripting retrying login in the client application FCM and GCM handle messages through the same instructions, however, instead of GCM connection servers, messages are passed through FCM servers  The FCM Software Development Kit (SDK) excludes writing individual registration or subscription retry logic for a shortened client development process  The FCM SDK provides a new notification solution allowing developers to use the serverless Firebase Notifications on a web console, based on Firebase Analytics insights  FCM enables unlimited upstream and downstream messages to be sent  Figure 5 10 : Cloud Messaging 50  CHAPTER 6 WORKING PRINCIPLES 6 1 INTRODUCTION When the system is first turned on, it checks to see if the user has selected surveillance mode  When a user activates the surveillance mode via a mobile app, the system activates as well  To detect any movements, the live feed from the webcam will be continuously evaluated using openCV and a backdrop comparison algorithm When motion is detected, the system takes a picture and sends it to the cloud API  The system will then start a self protection procedure by turning on the linked relays  The user will receive the warning message via the app  The image will be shown to the user during the time of motion  The image sensor is located within the camera and is where the camera lens focuses light  When light strikes the image sensor, each individual pixel registers how much light it receives  The sensitivity level or percentage level settings on the motion detection system define how much change is \"enough \" Higher sensitivity will detect more changes, but lesser sensitivity will need a significant amount of change, such as turning on the lights in a dark room, to trigger the alerts  The camera software compares successive photos from your video and evaluates if enough pixels have changed between those frames, indicating that something has moved and sending an alarm  To create foreground pictures, the background image is approximated and then removed from each video frame  The median will be increased or decreased by a factor that is proportional to the running standard deviation and the size of the time series data  Based on the new data sample, this algorithm will update the median value of the time series data  The moving objects in the first few image frames will 51 be identified by this technique, and the related pixels will be labeled as foreground pixels  The system estimates more and more background pixels as the foreground items move  The programme then recognises the pixels that do not belong to the foreground as the incomplete background  6 2 WORKFLOW 1  Initially , once the system is connected to the power , it will check whether the user has set the system into surveillance mode or not  2  If the user turns on the surveillance mode via a mobile app, the system will turn on to surveillance mode  3  The live feed from the webcam will be continuously checked using openCV and background comparison algorithm to find any motion  4  If any motion occurs the system immediately captures the image and sends it to the cloud API  5  Then the system itself will initiate a self protecting method by turning on the connected relays  6  The system will send the warning message to the user via app  User will get the image at the time of motion  6 3 MOTION DETECTION Motion detection is an important feature of the proposed system to secure the surveillance area  To understand motion detection, first you need to understand how a camera works  Inside the camera is an image sensor, which the camera lens directs light to   when light hits the image sensor each individual pixel records how much 52 light it\\'s getting  That pattern of light and dark areas on the pixels becomes the complete video image  When setting up motion detection, select a region or area to monitor, say a doorway  The way it works is to compare sequential images from your video and if enough of the pixels have changed between those frames, the camera software determines something moved and sends an alert  How \"enough\" change is determined depends on the sensitivity level or percentage level settings on the motion detection system  The sensitivity level looks at the changing light/dark levels in the pixels  Higher sensitivity will pick up on more changes while lower sensitivity will require a large level of change, such as the lights going on in a dark room, to set off the alerts  Percentage, on the other hand, looks to the percentage of pixels that have registered a change  If you are monitoring a door, setting the percentage at 50% will alert you when something is large  Figure 6 1 : Motion Tracking 6 4 MOTION DETECTION ALGORITHM Initially, We needed to create a VideoCapture object to read the frames from the input  That is, a Pi Cam video  If you want to work with another input file already saved on your PC, you can use the same  The first frame typically means it contains only the background  It is the reference frame of our program  If there is any difference in the current frame with respect to the first frame, it means motion is 53  detected  We store our first frame in the frame1 variable  So, The first line is to read the frame  We then convert the colored frame to B&W since we do not need colors to detect motion  Then we smooth out the image using GaussianBlur  Now we store the current frame in the frame2 variable and apply the same filters as our first frame  We need a loop since the read() method only captures one frame at a time  So, to capture a continuous video, we have to loop instructions  Now we compare our current frame with the first frame, to check if any motion is detected  The absdiff() method gives the absolute value of pixel intensity differences of two frames  The first parameter is the background frame and the second is the current frame  Now we have to threshold the data frame variable using the cv2 threshold() method  The first parameter is the frame to be thresholded  The second and third are the threshold limits and the last parameter is the method used  The THRESH_BINARY method paints the background in black and motion in white  The dilate() method removes all the gaps in between  Using contours, we can find the white images in the black background  We detect contours using the findContours() method  It returns two variables, contour and hierarchy, and the parameters passed to it are the threshold variable, retrieval method and approximation method  We now loop through the contour numpy array and draw a rectangle around the moving object  We get the rectangle bounds using boundingRect() and draw the rectangle onto frame2 using the rectangle() method  And the last lines of code waits for the user to enter a certain character, for instance ‘q’, to break out of the loop and quit all the windows  54 Figure 6 2 Motion Detection 6 5 BACKGROUND SUBTRACTION Detection of motion in many current tracking systems relies on the technique of background subtraction  Background subtraction is a widely used approach for detecting moving objects in videos recorded from static cameras  The background image must be such that it should not contain any moving objects and must be kept regularly updated to adapt the varying lighting conditions and geometry settings  By subtracting background images from the incoming video frames, the presence of an object and its motion can be tracked  Graphical representation of background subtraction technique is shown in the Figure 55  Figure 6 3 : Background subtraction The methods also exist for background estimation, which will establish the model of background for the subtraction  There is no need to update background images  Various techniques for background estimations are listed below  Estimating median over time :  This algorithm will update the median value of the time series data based upon the new data sample  The will increment or decrement the median by an amount that is related to the running standard deviation and the size of the time series data  The approach will also apply a correction to the median value if it detects a local ramp in the time series data  Overall, the estimated median is constrained within Chebyshev\\'s bounds, which are square root (3/5) of the standard deviation on either side of the mean of the data  Computing median over time :  This method will compute the median of the values at each pixel location over a time window of 30 frames  Eliminating moving objects   This algorithm will identify the moving objects in the first few image frames and label the corresponding pixels as foreground pixels  Next, the algorithm identifies the incomplete background as the pixels that do not belong to the foreground pixels  As the foreground objects move, the algorithm estimates more and more of the background pixels  56  The methods also exist for background estimation, which will establish the model of background for the subtraction  There is no need to update background images  Various techniques for background estimations are listed below  Estimating median over time   This algorithm will update the median value of the time series data based upon the new data sample  The will increment or decrement the median by an amount that is related to the running standard deviation and the size of the time series data  The approach will also apply a correction to the median value if it detects a local ramp in the time series data  Overall, the estimated median is constrained within Chebyshev\\'s bounds, which are square root (3/5) of the standard deviation on either side of the mean of the data  Computing median over time   This method will compute the median of the values at each pixel location over a time window of 30 frames  Eliminating moving objects   This algorithm will identify the moving objects in the first few image frames and label the corresponding pixels as foreground pixels  Next, the algorithm identifies the incomplete background as the pixels that do not belong to the foreground pixels  As the foreground objects move, the algorithm estimates more and more of the background pixels  Once the background image is estimated, it is subtracted from each video frame to produce foreground images  By thresholding and performing morphological closing on each foreground image, the model produces binary feature images The model locates the cars in each binary feature image and draws a green rectangle around the cars that pass beneath the white line  The counter in the upper left corner of Figure 2d tracks the number of cars in the region of interest 57 6 6 GAUSSIAN BLUR Gaussian blur (also known as Gaussian smoothing) is the result of blurring an image by a Gaussian Function  It is widely used to reduce noise and detail[20]  The visual effect of this blurring technique is a smooth blur resembling that of viewing the image through a translucent screen, distinctly different from the bake effect produced by an out of focus lens or the shadow of an object under usual illumination  Gaussian smoothing is also used as a pre processing stage in computer vision algorithms in order to enhance image structures at different scales  The equation of a Gaussian function in one dimension is:            (Equation 6 1) Grayscale is a range of shades of gray without apparent color  The darkest possible shade is black, which is the total absence of transmitted or reflected light  The lightest possible shade is white, the total transmission or reflection of light at all visible wavelengths   Intermediate shades of gray are represented by equal brightness levels of the three primary colors (red, green and blue) for transmitted light, or equal amounts of the three primary pigments (cyan, magenta and yellow) for reflected light  In the case of transmitted light (for example, the image on a computer display), the brightness levels of the red (R), green (G) and blue (B) components are each represented as a number from decimal 0 to 255, or binary 00000000 to 11111111  For every pixel in a red green blue ( RGB) grayscale image, R = G = B  The lightness of the gray is directly proportional to the number representing the brightness levels of the primary colors  58  6 7 TRAPPING THE TRESPASSER In the existing surveillance method, instead of surveillance there is no prevention method  Also, There is a chance of an attack on the surveillance system  That will completely lose the camera and connected system  The proposed system has a self protection feature to prevent any attack on the surveillance system  The motion detection system will trigger two separate relays  Here users can connect any prevention methods like door locking system, Chemical spraying, Industrial siren triggering, warning light etc depending on the user requirement  For Example  If the prevention mechanism is activated in any sensitive area  By taking the seriousness of the activity, System can easily trap the trespasser by activating any poisonous gas  Which makes them unconscious  Then, Make sure the doors are closed  Hence, It\\'s easy to trap the trespasser  Also, it prevents further movement and ensures security for the CCTV and related systems  6 8 ALERTS While running the system, It will send the live feed to android APP like a normal IP cam  Users can easily monitor the entire surrounding by just a click  The same system will check in a regular interval whether the user activated the motion detection  If it is in the activated state, The system will act as motion detection  Then the system will look for any motions on the video feed  If it is found, Will capture a picture of that moment and send the Image to the Flask API, which is hosted in Heroku  Then the heroku system will send the same to Firebase storage with a reference link to the image  The same will send a push notification to the user  To let them know about detection in real time  The application will make an alert sound  Users can easily access the captured image through the app itself  The same system will activate a few alert systems near to the camera itself  Buzzer and LED indicator will be activated once the system catches any anomaly  59 CHAPTER 7 RESULTS AND DISCUSSIONS 7 1 INTRODUCTION After successful completion of the project, following were the results that were obtained  When motion is detected, the system captures a picture and transmits it to the cloud API  The system will then start a self protection procedure by turning on the linked relays  The user will receive the warning notice via the app  The picture will be shown to the user during the time of motion  7 2 CAMERA FEED Figure 7 1 : Camera Test 1 60  Figure 7 2 : Camera Test 2 When the motion occurs the system immediately captures the image and sends it to the cloud API Then the system itself will initiate a self protecting method by turning on the connected relays  The system will send the warning message to the user via app  User will get the image at the time of motion  61  7 3 MOBILE APP Figure 7 4 : App UI 62  7 4 ALERT Figure 7 5 : App Notification and Alert 2 7 5 ADVANTAGES Advantages ● Easy to connect ● Uses Less Disk Space ● Easy to get notification on mobile phone ● Only required less resources and infrastructure ● Less power is required ● Less maintenance cost 63  CHAPTER 8 CONCLUSION AND FUTURE SCOPE 8 1 CONCLUSION The proposed system can easily be implemented and will provide a complete safety solution for surveillance systems  This project has designed a smart surveillance system which captures real time images and transmits them to the owner\\'s mobile phone  Detection of the theft can be done using the system  The system will prevent theft without any physical damage  After successfully completing the project, it may be used to detect motion for a smart home security system, which would be extremely useful in detecting auto theft for security purposes  It can also be useful at midnight in a bank, museum, or on the street  The same can be controlled from anywhere and prevention can execute easily  Real time video analysis provides smart surveillance systems with the ability to react in real time  This project also provides a device that can give authority to the user or owner to take actions against the alert message through options  Our system senses the intrusion and sends notifications to authorized persons so that action can be taken in response to the intrusion  One of the best features about our project is that it is easy to implement, low cost and easy to implement  8 2 FUTURE ENHANCEMENT Computer vision and image processing can be used to make a wide variety of applications  Adding extra features into the proposed system will be very useful for several future applications  Implementing this system for anomaly detection in a moving environment will make the system more efficient  Adding Face recognition with the system will make it more efficient  Can be very useful to fault triggering of the system from authorized people  As sensors enable previously lifeless common 64 things to become not just interactive, but also predictive, human connection with our surroundings will become more natural and intuitive In this system, we can add faces of known people, i e  people who can be trusted around that area other than the user  This could make the system more reliable as well as scalable  These sorts of systems will be employed in a wide range of consumer and industrial applications, from predictive maintenance and asset tracking to self driving automobiles, fully linked smart cities, and beyond  65 REFERENCES ● Nahum Kiryati, Tammy Riklin Raviv , Yan Ivanchenko, Shay Rochel , “Real time Abnormal Motion Detection in Surveillance Video”,19th International Conference on Pattern Recognition,Dec 2008  ● M  Valera and S A  Velastin, “Intelligent distributed surveillance systems: a review”  Vision, Image and Signal Processing, IEE Proceedings   (V olume:152 , Issue: 2 ),8 April 2005  ● Bhavana C  Bendale, Prof  Anil R  Karwankar , “Moving Object Tracking in Video Using MATLAB”,International Journal of Electronics, Communication & Soft Computing Science and Engineering,ISSN: 2277 9477, Volume 2, Issue 1,2013 ● C  Stauf fer and W  E  L  Grimson, (1999) ‘Adaptive Background Mixture Models for Real time Tracking’, in Proc  IEEE Conf  Computer Vision and Pattern Recognit , Vol 2, pp 246–252  ● J  D , “Real Time Embedded Network Video Capture And SMS Alerting system,” June 2014 ● S  Sneha, “IP Camera Video Surveillance using Raspberry Pi ,” Feb  2015 ● U  Kumar , R  Manda, S  Sai, and A  Pammi, “Implementation Of Low Cost Wireless Image Acquisition And Transfer To Web Client Using Raspberry Pi For Remote Monitoring  International Journal of Computer Networking, Wireless and Mobile Communications (IJCNWMC) ,” vol  No  4, no  3, pp  17–20, 2014  ● https://developer  android com/reference/android/webkit/W ebView ● https://pyimagesearch com/2018/09/26/install opencv 4 on your  raspber ry pi/ ● https://www  jeremymor gan com/tutorials/raspberry pi/how to install ope ncv raspberry pi/ ● https://medium com/google cloud/building a flask python crud api with  cloud firestore firebase and deploying on cloud run 29a10c502877 ● Richardson, M , & Wallace, S  (2012)  Getting started with raspberry PI  \" O\\'Reilly Media, Inc \"  66 ● Patel, P  B , Choksi, V  M , Jadhav, S , & Potdar, M  B  (2016)  Smart motion detection system using raspberry pi  International Journal of Applied Information Systems (IJAIS), 10(5), 37 40  ● Abaya, W  F , Basa, J , Sy, M , Abad, A  C , & Dadios, E  P  (2014, November)  Low cost smart security camera with night vision capability using Raspberry Pi and OpenCV  In 2014 International conference on humanoid, nanotechnology, information technology, communication and control, environment and management (HNICEM) (pp  1 6)  IEEE  ● Prasad, S , Mahalakshmi, P , Sunder, A  J  C , & Swathi, R  (2014)  Smart surveillance monitoring system using Raspberry Pi and PIR sensor  Int  J  Comput  Sci  Inf  Technol, 5(6), 7107 7109  ● Kumar, K  K , Natraj, H , & Jacob, T  P  (2017, April)  Motion activated security camera using Raspberry Pi  In 2017 International Conference on Communication and Signal Processing (ICCSP) (pp  1598 1601)  IEEE  ● Kaur, B , Pateriya, P  K , & Rai, M  K  (2018, April)  An illustration of making a home automation system using raspberry Pi and PIR sensor  In 2018 International Conference on Intelligent Circuits and Systems (ICICS) (pp  439 444)  IEEE  ● Iversen, T  K , Kristoffersen, K  J , Larsen, K  G , Laursen, M , Madsen, R  G , Mortensen, S  K ,     & Thomasen, C  B  (2000, June)  Modelchecking real time control programs: verifying lego mindstorms tm systems using uppaal  In Proceedings 12th Euromicro Conference on Real Time Systems  Euromicro RTS 2000 (pp  147 155)  IEEE  ● Y  Amit and P  Felzenszwalb, \"Object Detection\", Computer Vision, pp  537 542, 2014  ● \"Convolutional neural network\", En wikipedia org, 2019  [Online]  Available: https://en wikipedia org/wiki/Convolutional_neural_network  [Accessed: 10  Feb  2019] ● A  Krizhevsky, I  Sutskever and G  Hinton, \"ImageNet classification with deep convolutional neural networks\", Communications of the ACM, vol  60, no  6, pp  84 90, 017  ● \"What is a Raspberry Pi?\", Raspberry Pi, 2019  [Online]  Available: https://www raspberrypi org/help/what %20is a raspberry pi/  [Accessed: 06  Mar  2019] 67 ● J  Huang, V  Rathod, C  Sun, M  Zhu, A  Korattikara, A  Fathi, I  Fischer, Z  Wojna, Y  Song, S  Guadarrama, and K  Murphy, “Speed/Accuracy Trade Offs for Modern Convolutional Object Detectors,” 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2017  ● D  Velasco Montero, J  Fernández Berni, R  Carmona Galán and Á  Rodríguez Vázquez, \"Performance analysis of real time DNN inference on Raspberry Pi\", Real Time Image and Video Processing 2018, 2018  ● W  Liu, D  Anguelov, D  Erhan, C  Szegedy, S  Reed, C  Fu and A  Berg, \"SSD: Singlehot MultiBox Detector\", Computer Vision – ECCV 2016, pp  21 37, 2016  ● Redmon, J , & Farhadi, A  (2017)  YOLO9000: Better, Faster, Stronger  2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)  doi:10 1109/cvpr 2017 690 ● T  Y  Lin, M  Maire, S  Belongie, J  Hays, P  Perona, D  Ramanan, P  Dollár, and C  L  Zitnick, “Microsoft COCO: Common Objects in Context,” Computer Vision – ECCV 2014 Lecture Notes in Computer Science, pp  740–755, 2014  ● Y  Jia, E  Shelhamer, J  Donahue, S  Karayev, J  Long, R  Girshick, S  Guadarrama and T  Darrell, \"Caffe\", Proceedings of the ACM International Conference on Multimedia   MM \\'14, 2014  ● J  Redmon, \"Darknet: Open Source Neural Networks in C\", Pjreddie com, 2013 2016  [Online]  Available: https://pjreddie com/darknet/  [Accessed: 22  Apr  2019] ● Abadi, M  et al , “Tensorflow: A system for large scale machine learning,” in [12th USENIX Symposium on Operating Systems Design and Implementation (OSDI 16) ], 265–283 (2016)  ● S  Mallick, \"CPU Performance Comparison of OpenCV and other Deep Learning frameworks | Learn OpenCV\", Learnopencv com, 2019  [Online]  Available: https://www learnopencv com/cpu performance comparison of opencv and o ther deep learning frameworks/#object detection  [Accessed: 08  Sep  2019]  ● GitHub  (2019)  Tensorflow detection model zoo  [online] Available at: https://github com/tensorflow/models/blob/master/research/object_detection/ g3doc/detection_model_zoo md#coco trained models [Accessed 20 May 2019]  68 PUBLICATIONS JOURNAL PUBLICA TIONS: Published the paper entitled “AUTOMATIC THREAT DETECTION AND THEFT TRAPPING THROUGH VIDEO SURVEILLANCE SYSTEM” in the Dickensian Journal UGC CARE Approved Group ‘II’ Journal,Volume 22,issue 5,2022 Page No: 1100 1103,DOI:10 12001 DK J2022 V22 15 293 May 2022 CONFERENCE PUBLICA TION: Presented the paper entitled “ AUTOMATIC THREAT DETECTION AND THEFT TRAPPING THROUGH VIDEO SURVEILLANCE SYSTEM” , in the national conference on“RECENT ADVANCED IN ELECTRICAL,ELECTRONICS AND COMMUNICATION NETWORKS” on 27th may 2022 held at HINDUSTHAN INSTITUTE OF TECHNOLOGY ,Coimbatore 69', 15210)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "pattern = re.compile(r'\\n|\\-|\\.|\\s+')\n",
    "text = pattern.subn(' ',data)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a019dfc7-fce3-4612-a305-fed2f5ee423e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_pdf_data('table.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "460d624e-4067-41d8-9cde-50a9f01fef76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Example table  \\nThis is an example of a data table. \\nDisability \\nCategory Participants  Ballots \\nCompleted  Ballots \\nIncomplete/  \\nTerminated  Results  \\nAccuracy  Time to \\ncomplete \\nBlind  5 1 4 34.5%, n=1  1199 sec, n=1  \\nLow Vision  5 2 3 98.3% n=2  \\n(97.7%, n=3)  1716 sec, n=3  \\n(1934 sec, n=2)  \\nDexterity  5 4 1 98.3%, n=4  1672.1 sec, n=4  \\nMobility  3 3 0 95.4%, n=3  1416 sec, n=3  \\n '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "299701fd-9f70-4fe3-950a-93e5b0ff0b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern1 = re.compile('\\n')\n",
    "\n",
    "dat = pattern1.sub(' ',data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c240d6a-b8e7-4a17-a039-d98169ae54a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Example table   This is an example of a data table.  Disability  Category Participants  Ballots  Completed  Ballots  Incomplete/   Terminated  Results   Accuracy  Time to  complete  Blind  5 1 4 34.5%, n=1  1199 sec, n=1   Low Vision  5 2 3 98.3% n=2   (97.7%, n=3)  1716 sec, n=3   (1934 sec, n=2)   Dexterity  5 4 1 98.3%, n=4  1672.1 sec, n=4   Mobility  3 3 0 95.4%, n=3  1416 sec, n=3    '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c69205b2-2f25-4f07-9e09-8658c6111b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "invoice =get_pdf_data('OD125682207235841000.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0d1ff33f-90f5-45cb-9e0a-0a360caa9841",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E. & O.E. page 1 of 1\\n*Keep this invoice and \\nmanufacturer box for \\nwarranty purposes.Ship To\\nJayesh Pt \\nBrototype, Room No.III/9, 3rd Floor, \\nSDF Building, Kinfra Techno \\nIndustrialpark Calicut University PO, \\nKakkanchery,.\\nThenhippalam 673635 Kerala \\nPhone: xxxxxxxxxx Bill To\\nJayesh Pt \\nBrototype, Room No.III/9, 3rd Floor, \\nSDF Building, Kinfra Techno \\nIndustrialpark Calicut University PO, \\nKakkanchery,.\\nThenhippalam 673635 Kerala \\nPhone: xxxxxxxxxx Order ID: OD125682207235841000\\n 08-08-2022 Order Date:\\n 08-08-2022 Invoice Date:\\n AAJCM4219P PAN:\\nInvoice Number # FAJHVF2300065809Tax Invoice\\nSold By:  MPS Telecom Retail Private Limited ,\\nShip-from Address:  NDR warehousing private ltd, SF No. 525, 526, 529-533, Okilipalayam, , Palladam Road, Othakalmandapam, , \\nCoimbatore, Tamilnadu, India - 641032, IN-TN\\nGSTIN  - 33AAJCM4219P3Z2\\nTotal items: 1\\nProduct Title Qty Gross\\nAmount ₹Discounts\\n/Coupons ₹Taxable\\nValue ₹IGST ₹ Total ₹\\nTrue Wireless\\nFSN: ACCGDGPDGEY3EXG8\\nHSN/SAC: 85176290OnePlus Nord Buds \\nBluetooth Headset\\nWarranty: 1 Year Warranty\\n 18.0 % IGST:1 2599.00 0.00 2202.54 396.46 2599.00\\nShipping And Convenience Charges 1 40.00 -40.00 0.00 0.00 0.00\\nTotal 1 2639.00 -40.00 2202.54 396.46 2599.00\\nGrand Total ₹ 2599.00\\nMPS Telecom Retail Private Limited\\nSignature\\nAuthorized Signatory\\n: At Flipkart we try to deliver perfectly each and every time. But in the off-chance that you need to return the item, please do so with the Returns Policy original Brand box/price \\n without which it will be really difficult for us to act on your request. Please help us in helping you. Terms and conditions apply. tag, original packing and invoice\\nThe goods sold as are intended for end user consumption and not for re-sale.\\nRegd. office:  , No B1 632, 2nd and 3rd floor, Co Offiz Coworking space, Janakpuri, Delhi, Delhi - 110058 MPS Telecom Retail Private Limited\\nContact Flipkart: 1800 208 9898 || www.flipkart.com/helpcentre'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "invoice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ddde736-00e0-4dfc-975a-f81f9b061f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pattern1.sub('',invoice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ab2ec9a6-7d5a-4df0-b055-e3bd2a33c662",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E. & O.E. page 1 of 1*Keep this invoice and manufacturer box for warranty purposes.Ship ToJayesh Pt Brototype, Room No.III/9, 3rd Floor, SDF Building, Kinfra Techno Industrialpark Calicut University PO, Kakkanchery,.Thenhippalam 673635 Kerala Phone: xxxxxxxxxx Bill ToJayesh Pt Brototype, Room No.III/9, 3rd Floor, SDF Building, Kinfra Techno Industrialpark Calicut University PO, Kakkanchery,.Thenhippalam 673635 Kerala Phone: xxxxxxxxxx Order ID: OD125682207235841000 08-08-2022 Order Date: 08-08-2022 Invoice Date: AAJCM4219P PAN:Invoice Number # FAJHVF2300065809Tax InvoiceSold By:  MPS Telecom Retail Private Limited ,Ship-from Address:  NDR warehousing private ltd, SF No. 525, 526, 529-533, Okilipalayam, , Palladam Road, Othakalmandapam, , Coimbatore, Tamilnadu, India - 641032, IN-TNGSTIN  - 33AAJCM4219P3Z2Total items: 1Product Title Qty GrossAmount ₹Discounts/Coupons ₹TaxableValue ₹IGST ₹ Total ₹True WirelessFSN: ACCGDGPDGEY3EXG8HSN/SAC: 85176290OnePlus Nord Buds Bluetooth HeadsetWarranty: 1 Year Warranty 18.0 % IGST:1 2599.00 0.00 2202.54 396.46 2599.00Shipping And Convenience Charges 1 40.00 -40.00 0.00 0.00 0.00Total 1 2639.00 -40.00 2202.54 396.46 2599.00Grand Total ₹ 2599.00MPS Telecom Retail Private LimitedSignatureAuthorized Signatory: At Flipkart we try to deliver perfectly each and every time. But in the off-chance that you need to return the item, please do so with the Returns Policy original Brand box/price  without which it will be really difficult for us to act on your request. Please help us in helping you. Terms and conditions apply. tag, original packing and invoiceThe goods sold as are intended for end user consumption and not for re-sale.Regd. office:  , No B1 632, 2nd and 3rd floor, Co Offiz Coworking space, Janakpuri, Delhi, Delhi - 110058 MPS Telecom Retail Private LimitedContact Flipkart: 1800 208 9898 || www.flipkart.com/helpcentre'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03e09396-5303-4795-adf1-39a52d3dd868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['673635',\n",
       " '673635',\n",
       " '125682',\n",
       " '207235',\n",
       " '841000',\n",
       " '230006',\n",
       " '641032',\n",
       " '851762',\n",
       " '110058']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(\"\\d{6}\")\n",
    "\n",
    "pincode = pattern.findall(data)\n",
    "pincode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96a358bc-563b-4fe5-bd78-7efaee3f511b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['08-08-2022', '08-08-2022']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(r\"\\b\\d{2}-\\d{2}-\\d{4}\\b\")\n",
    "\n",
    "date = pattern.findall(data)\n",
    "date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e297919f-a227-42bb-b982-aad21f62cd77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['529-533']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = re.compile(r\"\\b\\d{3}-\\d{3}\\b\")\n",
    "phone = pattern.findall(data)\n",
    "phone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "073e6dad-6bcb-4667-93d8-393b581e61a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = re.compile(r'\\b\\d{4} \\d{3} \\d{4}\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e925d2e-0d92-45dd-bcc2-6e9015173ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1800 208 9898']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tollfree = pattern.findall(data)\n",
    "tollfree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9b927bf-1c4f-43b1-b630-8580ecd4c99c",
   "metadata": {},
   "source": [
    "### How to Extract PDF Tables in Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "228cf5d2-627f-40f6-b7fc-a2f0478969e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabula import read_pdf\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06971a6f-981e-4909-8b9d-85502b8fda8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "JavaNotFoundError",
     "evalue": "`java` command is not found from this Python process.Please ensure Java is installed and PATH is set for `java`",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tabula\\io.py:88\u001b[0m, in \u001b[0;36m_run\u001b[1;34m(java_options, options, path, encoding)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 88\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     89\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     92\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDEVNULL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     93\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m result\u001b[38;5;241m.\u001b[39mstderr:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\subprocess.py:505\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    503\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstderr\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m PIPE\n\u001b[1;32m--> 505\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Popen(\u001b[38;5;241m*\u001b[39mpopenargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\subprocess.py:951\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask)\u001b[0m\n\u001b[0;32m    948\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m    949\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m--> 951\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    952\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    953\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    954\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    955\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    956\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    957\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    958\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    959\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    960\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m    961\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\subprocess.py:1420\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session)\u001b[0m\n\u001b[0;32m   1419\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1420\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1421\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1422\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1423\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1424\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1425\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1426\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1427\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1428\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1429\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1430\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1433\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mJavaNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mread_pdf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFood Calories List.pdf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mpages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tabulate(df))\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tabula\\io.py:425\u001b[0m, in \u001b[0;36mread_pdf\u001b[1;34m(input_path, output_format, encoding, java_options, pandas_options, multiple_tables, user_agent, use_raw_url, pages, guess, area, relative_area, lattice, stream, password, silent, columns, relative_columns, format, batch, output_path, options)\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is empty. Check the file, or download it manually.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    424\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 425\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjava_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtabula_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m temporary:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\tabula\\io.py:99\u001b[0m, in \u001b[0;36m_run\u001b[1;34m(java_options, options, path, encoding)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\u001b[38;5;241m.\u001b[39mstdout\n\u001b[0;32m     98\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m:\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JavaNotFoundError(JAVA_NOT_FOUND_ERROR)\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m subprocess\u001b[38;5;241m.\u001b[39mCalledProcessError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    101\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError from tabula-java:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mdecode(encoding)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mJavaNotFoundError\u001b[0m: `java` command is not found from this Python process.Please ensure Java is installed and PATH is set for `java`"
     ]
    }
   ],
   "source": [
    "df = read_pdf('Food Calories List.pdf',pages=\"all\")\n",
    "print(tabulate(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e156ec76-c54f-441d-8ce0-af1e36337ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a91d5b-2f68-4081-984c-014a524d6c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92cac3-4bb3-4fad-a65b-8158598d5bf9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11633d6b-1648-4640-bd63-56a37a882d02",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5660b03e-8bd6-4da5-91e5-3a834e461aa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9b1d9a-5412-466f-ae77-a7ceec28a20d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2fc518a7-8832-4b18-b6d5-9082604f9144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: camelot-py[cv] in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from camelot-py[cv]) (0.9.0)\n",
      "Requirement already satisfied: chardet>=3.0.4 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from camelot-py[cv]) (5.1.0)\n",
      "Requirement already satisfied: pandas>=0.23.4 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from camelot-py[cv]) (1.5.3)\n",
      "Requirement already satisfied: pdfminer.six>=20200726 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from camelot-py[cv]) (20221105)\n",
      "Requirement already satisfied: openpyxl>=2.5.8 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from camelot-py[cv]) (3.1.2)\n",
      "Requirement already satisfied: pypdf>=3.0.0 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from camelot-py[cv]) (3.5.2)\n",
      "Requirement already satisfied: click>=6.7 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from camelot-py[cv]) (8.1.3)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from camelot-py[cv]) (1.24.2)\n",
      "Requirement already satisfied: ghostscript>=0.7 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from camelot-py[cv]) (0.7)\n",
      "Requirement already satisfied: pdftopng>=0.2.3 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from camelot-py[cv]) (0.2.3)\n",
      "Requirement already satisfied: opencv-python>=3.4.2.17 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from camelot-py[cv]) (4.7.0.72)\n",
      "Requirement already satisfied: colorama in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from click>=6.7->camelot-py[cv]) (0.4.6)\n",
      "Requirement already satisfied: setuptools>=38.6.0 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from ghostscript>=0.7->camelot-py[cv]) (65.6.3)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from openpyxl>=2.5.8->camelot-py[cv]) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from pandas>=0.23.4->camelot-py[cv]) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from pandas>=0.23.4->camelot-py[cv]) (2022.7.1)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from pdfminer.six>=20200726->camelot-py[cv]) (39.0.1)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from pdfminer.six>=20200726->camelot-py[cv]) (3.0.1)\n",
      "Requirement already satisfied: typing_extensions>=3.10.0.0 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from pypdf>=3.0.0->camelot-py[cv]) (4.4.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six>=20200726->camelot-py[cv]) (1.15.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from python-dateutil>=2.8.1->pandas>=0.23.4->camelot-py[cv]) (1.16.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six>=20200726->camelot-py[cv]) (2.21)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade camelot-py[cv]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d55b9a57-da72-4c6e-9995-cb5a3167cba0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'COMMON_SAFE_ASCII_CHARACTERS' from 'charset_normalizer.constant' (C:\\Users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages\\charset_normalizer\\constant.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcamelot\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m data \u001b[38;5;241m=\u001b[39m camelot\u001b[38;5;241m.\u001b[39mread_pdf(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFood Calories List.pdf\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\camelot\\__init__.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m__version__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m read_pdf\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mplotting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PlotMethods\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# set up logging\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\camelot\\io.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhandlers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PDFHandler\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validate_input, remove_extra\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_pdf\u001b[39m(\n\u001b[0;32m     10\u001b[0m     filepath,\n\u001b[0;32m     11\u001b[0m     pages\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m     17\u001b[0m ):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\camelot\\handlers.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpypdf\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PdfReader, PdfWriter\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TableList\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mparsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Stream, Lattice\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m     11\u001b[0m     TemporaryDirectory,\n\u001b[0;32m     12\u001b[0m     get_page_layout,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     16\u001b[0m     download_url,\n\u001b[0;32m     17\u001b[0m )\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPDFHandler\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\camelot\\parsers\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstream\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Stream\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlattice\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Lattice\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\camelot\\parsers\\stream.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseParser\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TextEdges, Table\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m text_in_bbox, get_table_index, compute_accuracy, compute_whitespace\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\camelot\\parsers\\base.py:5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# -*- coding: utf-8 -*-\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_page_layout, get_text_objects\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mBaseParser\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;124;03m\"\"\"Defines a base parser.\"\"\"\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\camelot\\utils.py:14\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01moperator\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m itemgetter\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpdfminer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdfparser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PDFParser\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpdfminer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdfdocument\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PDFDocument\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpdfminer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdfpage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PDFPage\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\pdfminer\\pdfparser.py:6\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BinaryIO, TYPE_CHECKING, Optional, Union\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m settings\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdftypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PDFException\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdftypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PDFObjRef\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpdftypes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PDFStream\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\pdfminer\\pdftypes.py:22\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mccitt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ccittfaxdecode\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlzw\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m lzwdecode\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpsparser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LIT\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpsparser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PSException\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpsparser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PSObject\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\pdfminer\\psparser.py:22\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m      8\u001b[0m     Any,\n\u001b[0;32m      9\u001b[0m     BinaryIO,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     18\u001b[0m     Union,\n\u001b[0;32m     19\u001b[0m )\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m settings\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m choplist\n\u001b[0;32m     24\u001b[0m log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mPSException\u001b[39;00m(\u001b[38;5;167;01mException\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\pdfminer\\utils.py:31\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m TYPE_CHECKING:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayout\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LTComponent\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m  \u001b[38;5;66;03m# For str encoding detection\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# from sys import maxint as INF doesn't work anymore under Python3, but PDF\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# still uses 32 bits ints\u001b[39;00m\n\u001b[0;32m     35\u001b[0m INF \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m<<\u001b[39m \u001b[38;5;241m31\u001b[39m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\charset_normalizer\\__init__.py:23\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124;03mCharset-Normalizer\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03m~~~~~~~~~~~~~~\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;124;03m:license: MIT, see LICENSE for more details.\u001b[39;00m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m from_fp, from_path, from_bytes, normalize\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlegacy\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m detect\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mversion\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__, VERSION\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\charset_normalizer\\api.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m     PathLike \u001b[38;5;241m=\u001b[39m Union[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mos.PathLike[str]\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TOO_SMALL_SEQUENCE, TOO_BIG_SEQUENCE, IANA_SUPPORTED\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmd\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mess_ratio\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CharsetMatches, CharsetMatch\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwarnings\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m warn\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\env\\lib\\site-packages\\charset_normalizer\\md.py:5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtyping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Optional, List\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconstant\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m UNICODE_SECONDARY_RANGE_KEYWORD\n\u001b[1;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcharset_normalizer\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m is_punctuation, is_symbol, unicode_range, is_accentuated, is_latin, \\\n\u001b[0;32m      6\u001b[0m     remove_accent, is_separator, is_cjk, is_case_variable, is_hangul, is_katakana, is_hiragana, is_ascii, is_thai\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mMessDetectorPlugin\u001b[39;00m:\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124;03m    Base abstract class used for mess detection plugins.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124;03m    All detectors MUST extend and implement given methods.\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'COMMON_SAFE_ASCII_CHARACTERS' from 'charset_normalizer.constant' (C:\\Users\\jayes\\anaconda3\\envs\\env\\lib\\site-packages\\charset_normalizer\\constant.py)"
     ]
    }
   ],
   "source": [
    "import camelot\n",
    "import pandas as pd\n",
    "\n",
    "data = camelot.read_pdf(\"Food Calories List.pdf\")\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25259c1-2eb5-43f1-8f77-4c34501ee88d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5b4afe-4907-4609-92fa-57271ae61d5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
