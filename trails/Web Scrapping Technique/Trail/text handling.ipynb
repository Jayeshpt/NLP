{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a540ed9b-5dea-4783-8dde-10b40d12d1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteer editors, known as Wikipedians, through open collaboration and using a wiki-based editing? system called MediaWiki. Wikipedia is the largest and most-read reference work in history\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "31688681-2797-47ba-aa1a-2f854cc0c869",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"newfile.txt\",'w') as file:\n",
    "    file.write(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e20f29f-ac2c-4069-b18e-7119b24637aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"newfile.txt\",\"r\") as file:\n",
    "    content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "741d45cb-138f-4436-9276-f5c1a3c6e779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteer editors, known as Wikipedians, through open collaboration and using a wiki-based editing? system called MediaWiki. Wikipedia is the largest and most-read reference work in history\n"
     ]
    }
   ],
   "source": [
    "print(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fb6538-b7a4-4281-afda-bb478c139afd",
   "metadata": {},
   "source": [
    "how to Alter the txt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "40c87841-fb17-4d9f-a3cb-1a931111a1b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"newfile.txt\",\"w\") as file:\n",
    "    file.write(\"NEw thing are coming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d614bda-83e6-4c7e-881c-b0676d4d056d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEw thing are coming\n"
     ]
    }
   ],
   "source": [
    "with open(\"newfile.txt\",\"r\")as file:\n",
    "    f1 = file.read()\n",
    "    print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba6793c3-a3aa-4d30-a471-e6d3fade6ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"newfile.txt\",\"a\") as file:\n",
    "    file.write(text)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2d29f68d-e712-4b0f-8c90-40d90d61cffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEw thing are comingWikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteer editors, known as Wikipedians, through open collaboration and using a wiki-based editing? system called MediaWiki. Wikipedia is the largest and most-read reference work in history\n"
     ]
    }
   ],
   "source": [
    "with open('newfile.txt','r') as file:\n",
    "    fil = file.read()\n",
    "    print(fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b27e29e0-2312-4867-84a5-46fe44199c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('newfile.txt','a') as file:\n",
    "    fill = file.write('  .you are soo great')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c595ba07-2f5a-46e6-a298-a5e9faec928a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEw thing are comingWikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteer editors, known as Wikipedians, through open collaboration and using a wiki-based editing? system called MediaWiki. Wikipedia is the largest and most-read reference work in history  .you are soo great\n"
     ]
    }
   ],
   "source": [
    "with open(\"newfile.txt\",\"r\") as file:\n",
    "    faa = file.read()\n",
    "    print(faa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89df78ac-14bf-4609-997a-eb0041f3675b",
   "metadata": {},
   "source": [
    "### Tokenization without libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "141dc786-546b-4b7a-a5a0-deaf29bfa71e",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEw\n",
      "thing\n",
      "are\n",
      "comingWikipedia\n",
      "is\n",
      "a\n",
      "multilingual\n",
      "free\n",
      "online\n",
      "encyclopedia\n",
      "written\n",
      "and\n",
      "maintained\n",
      "by\n",
      "a\n",
      "community\n",
      "of\n",
      "volunteer\n",
      "editors,\n",
      "known\n",
      "as\n",
      "Wikipedians,\n",
      "through\n",
      "open\n",
      "collaboration\n",
      "and\n",
      "using\n",
      "a\n",
      "wiki-based\n",
      "editing?\n",
      "system\n",
      "called\n",
      "MediaWiki.\n",
      "Wikipedia\n",
      "is\n",
      "the\n",
      "largest\n",
      "and\n",
      "most-read\n",
      "reference\n",
      "work\n",
      "in\n",
      "history\n",
      ".you\n",
      "are\n",
      "soo\n",
      "great\n"
     ]
    }
   ],
   "source": [
    "with open(\"newfile.txt\",'r') as file:\n",
    "    text = file.read()\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d405f4da-19b6-4053-a477-a94163c75360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEw thing are comingWikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteer editors\n",
      " known as Wikipedians\n",
      " through open collaboration and using a wiki-based editing\n",
      " system called MediaWiki\n",
      " Wikipedia is the largest and most-read reference work in history  \n",
      "you are soo great\n"
     ]
    }
   ],
   "source": [
    "### sentense tokenization without any library\n",
    "\n",
    "\n",
    "import re\n",
    "\n",
    "with open(\"newfile.txt\",'r') as file:\n",
    "    text = file.read()\n",
    "    sentenses = re.split(\"\\.|\\,|\\?\",text)\n",
    "    for sentense in sentenses:\n",
    "        print(sentense)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fa9f76-8b36-434d-b2b3-50b5767b1b48",
   "metadata": {},
   "source": [
    "#### Tokenization with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c9d4a4f9-a83b-43b5-ad34-40620ee4099a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEw', 'thing', 'are', 'comingWikipedia', 'is', 'a', 'multilingual', 'free', 'online', 'encyclopedia', 'written', 'and', 'maintained', 'by', 'a', 'community', 'of', 'volunteer', 'editors', ',', 'known', 'as', 'Wikipedians', ',', 'through', 'open', 'collaboration', 'and', 'using', 'a', 'wiki-based', 'editing', '?', 'system', 'called', 'MediaWiki', '.', 'Wikipedia', 'is', 'the', 'largest', 'and', 'most-read', 'reference', 'work', 'in', 'history', '.you', 'are', 'soo', 'great']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "with open(\"newfile.txt\",'r') as file:\n",
    "    text = file.read()\n",
    "    tokens = word_tokenize(text)\n",
    "    print(tokens)\n",
    "    \n",
    "with open(\"new tokens.txt\",'w') as file:\n",
    "    file.write(''.join(tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf59203e-a875-4dc0-869d-926914f486ac",
   "metadata": {},
   "source": [
    "sentense tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6a74a82d-669e-49a0-8559-6d832ba35b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NEw thing are comingWikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteer editors, known as Wikipedians, through open collaboration and using a wiki-based editing?', 'system called MediaWiki.', 'Wikipedia is the largest and most-read reference work in history  .you are soo great']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "with open('newfile.txt','r') as file:\n",
    "    text = file.read()\n",
    "    sent_tokens = sent_tokenize(text)\n",
    "    print(sent_tokens)\n",
    "    \n",
    "with open(\"new_sent_tokens.txt\",'w') as file:\n",
    "    file.write(''.join(sent_tokens))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13b1fe9-a4d1-4027-b95e-44018a7f1a8e",
   "metadata": {},
   "source": [
    "#### Tokenization using Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5692aeb4-47a8-48d0-b76c-6fdec8533c04",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEw\n",
      "thing\n",
      "are\n",
      "comingWikipedia\n",
      "is\n",
      "a\n",
      "multilingual\n",
      "free\n",
      "online\n",
      "encyclopedia\n",
      "written\n",
      "and\n",
      "maintained\n",
      "by\n",
      "a\n",
      "community\n",
      "of\n",
      "volunteer\n",
      "editors\n",
      ",\n",
      "known\n",
      "as\n",
      "Wikipedians\n",
      ",\n",
      "through\n",
      "open\n",
      "collaboration\n",
      "and\n",
      "using\n",
      "a\n",
      "wiki\n",
      "-\n",
      "based\n",
      "editing\n",
      "?\n",
      "system\n",
      "called\n",
      "MediaWiki\n",
      ".\n",
      "Wikipedia\n",
      "is\n",
      "the\n",
      "largest\n",
      "and\n",
      "most\n",
      "-\n",
      "read\n",
      "reference\n",
      "work\n",
      "in\n",
      "history\n",
      " \n",
      ".you\n",
      "are\n",
      "soo\n",
      "great\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "with open('newfile.txt','r') as file:\n",
    "    text = file.read()\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    for token in doc:\n",
    "        print(token.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "282db7e7-d41c-4f07-a7e0-ef9b0cfa4b23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEw thing are comingWikipedia is a multilingual free online encyclopedia written and maintained by a community of volunteer editors, known as Wikipedians, through open collaboration and using a wiki-based editing?\n",
      "system called MediaWiki.\n",
      "Wikipedia is the largest and most-read reference work in history  \n",
      ".you are soo great\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "with open(\"newfile.txt\",\"r\") as file:\n",
    "    text = file.read()\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    for sent in doc.sents:\n",
    "        print(sent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5d9f3a-af22-4b72-8c0c-40ec0ef4e610",
   "metadata": {},
   "source": [
    "### Removing white Space and Stopword without library and with NLTK and Spacy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "977824ed-7c87-49d2-9be4-a3fa9d4c70d9",
   "metadata": {},
   "source": [
    "#### without Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2d78e0a-941f-4c9e-bc36-aa5450fb26e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEwthingarecomingWikipediaisamultilingualfreeonlineencyclopediawrittenandmaintainedbyacommunityofvolunteereditors,knownasWikipedians,throughopencollaborationandusingawiki-basedediting?systemcalledMediaWiki.Wikipediaisthelargestandmost-readreferenceworkinhistory.youaresoogreat\n"
     ]
    }
   ],
   "source": [
    "with open('newfile.txt',\"r\") as file:\n",
    "    text = file.read()\n",
    "    # removing whitespace\n",
    "    text = ''.join(text.split())\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da3c6a17-74ea-4084-b698-671c438f4f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEw thing comingWikipedia multilingual free online encyclopedia written maintained community volunteer editors, known Wikipedians, through open collaboration using wiki-based editing? system called MediaWiki. Wikipedia largest most-read reference work history .you soo great \n"
     ]
    }
   ],
   "source": [
    "# removing stopwords \n",
    "\n",
    "# 1st need to defind stopwords\n",
    "stopwords = ['are','is','a','and','by','a','of','as','the','in']\n",
    "\n",
    "with open('newfile.txt',\"r\") as file:\n",
    "    text = file.read()\n",
    "# Remove stopwords\n",
    "filtered_text = \"\"\n",
    "words = text.split()\n",
    "for word in words:\n",
    "    if word.lower() not in stopwords:\n",
    "        filtered_text += word +\" \"\n",
    "print(filtered_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15abe224-b203-4959-9d27-acc0dd75623a",
   "metadata": {},
   "source": [
    "#### with NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "5084cbd8-b02c-4529-ab37-9cf24bf92bc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEw thing comingWikipedia multilingual free online encyclopedia written maintained community volunteer editors, known Wikipedians, open collaboration using wiki-based editing? system called MediaWiki. Wikipedia largest most-read reference work history .you soo great\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "#difine stopwords\n",
    "stopwords=set(stopwords.words('english'))\n",
    "\n",
    "with open('newfile.txt','r') as file:\n",
    "    text = file.read()\n",
    "    words = text.split()\n",
    "    \n",
    "    # remove stopwords\n",
    "    filteredwords= [word for word in words if word.lower() not in stopwords]\n",
    "    filteredtext = ' '.join(filteredwords)\n",
    "    print(filteredtext)\n",
    "    \n",
    "# Remove stopwords\n",
    "# filtered_text = \"\"\n",
    "# for word in words:\n",
    "#     if word.lower() not in stopwords:\n",
    "#         filtered_text += word +\" \"\n",
    "# print(filtered_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811008ff-4c2e-40b6-aa33-2212ff3b98fd",
   "metadata": {},
   "source": [
    "#### With spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f30c1474-6b13-4220-8a35-34e42e0a6a26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEw thing comingWikipedia multilingual free online encyclopedia written maintained community volunteer editors , known Wikipedians , open collaboration wiki - based editing ? system called MediaWiki . Wikipedia largest - read reference work history   .you soo great\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp=spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "with open(\"newfile.txt\",'r') as file:\n",
    "    text = file.read()\n",
    "    \n",
    "# Tokenize text using spacy\n",
    "    doc = nlp(text)\n",
    "\n",
    "# Remove stopwords\n",
    "    filtered_tokens = [token.text for token in doc if not token.is_stop]\n",
    "\n",
    "    filteredtext = ' '.join(filtered_tokens)\n",
    "\n",
    "    print(filteredtext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177a0a34-1b49-4b29-9427-bfd93c32914f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
