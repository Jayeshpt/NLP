{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef48629f-391d-42d2-a5fa-14ae4f48ad39",
   "metadata": {},
   "source": [
    "## Token Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20c528ed-3406-44e3-857f-1851d3d48fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'complex_example', ',', '!']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"A complex_example,!\")\n",
    "print([token.text for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "448917cd-7c3a-4458-93fa-bf8093e83dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_id : 15578876784678163569 \n",
      "string_id: HelloWorld \n",
      "start and end: 9 12 \n",
      "span.text: Hello, world \n",
      "\n",
      "match_id : 15578876784678163569 \n",
      "string_id: HelloWorld \n",
      "start and end: 32 34 \n",
      "span.text: hello world \n",
      "\n",
      "match_id : 15578876784678163569 \n",
      "string_id: HelloWorld \n",
      "start and end: 49 51 \n",
      "span.text: hello world \n",
      "\n",
      "match_id : 15578876784678163569 \n",
      "string_id: HelloWorld \n",
      "start and end: 107 109 \n",
      "span.text: hello world \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern =[ [{\"LOWER\":\"hello\"},{\"IS_PUNCT\":True},{\"LOWER\":\"world\"}],\n",
    "          [{\"LOWER\":\"hello\",},{\"LOWER\":\"world\"}]\n",
    "         ]\n",
    "matcher.add(\"HelloWorld\",pattern)\n",
    "\n",
    "doc = nlp(\"The programmer greeted the world with a cheerful 'Hello, world!' as they embarked on their coding journey. Little did they know that this simple phrase, 'hello world,' would become a cornerstone of their programming career. From their first 'hello world' program to complex software projects, the programmer never forgot the humble origins of those two words. 'Hello' and 'world' may seem ordinary, but together they carry the power to initiate a magical connection between humans and machines. So, let us all embrace the spirit of 'hello world' and explore the endless possibilities of coding!\")\n",
    "matches = matcher(doc)\n",
    "for match_id,start,end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id] # get string representation\n",
    "    span = doc[start:end] # the matches span\n",
    "    print(\"match_id :\",match_id,'\\nstring_id:',string_id,'\\nstart and end:',start,end,\"\\nspan.text:\",span.text,'\\n')\n",
    "    # match_id is the hash value of the string ID \"HelloWorld\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d792b0f7-5380-4bed-a5d9-419d833a259e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "match_id: 15578876784678163569 \n",
      "string_id: HelloWorld \n",
      "start and end: 9 12 \n",
      "span.text: Hello, world\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [\n",
    "    [{\"LOWER\": \"hello\"}, {\"IS_PUNCT\": True}, {\"LOWER\": \"world\"}]\n",
    "]\n",
    "matcher.add(\"HelloWorld\", pattern)\n",
    "\n",
    "doc = nlp(\"The programmer greeted the world with a cheerful 'Hello, world!' as they embarked on their coding journey. Little did they know that this simple phrase, 'hello world,' would become a cornerstone of their programming career. From their first 'hello world' program to complex software projects, the programmer never forgot the humble origins of those two words. 'Hello' and 'world' may seem ordinary, but together they carry the power to initiate a magical connection between humans and machines. So, let us all embrace the spirit of 'hello world' and explore the endless possibilities of coding!\")\n",
    "matches = matcher(doc)\n",
    "\n",
    "for match_id, start, end in matches:\n",
    "    string_id = nlp.vocab.strings[match_id]  # get string representation\n",
    "    span = doc[start:end]  # the matches span\n",
    "    print(\"match_id:\", match_id, \"\\nstring_id:\", string_id, \"\\nstart and end:\", start, end, \"\\nspan.text:\", span.text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acd5106a-e892-4366-a544-f1037c0e5b43",
   "metadata": {},
   "source": [
    "## Regex matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f2477076-258c-4b77-8c74-43f9a96ce3ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match: United States\n",
      "Found match: United States\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"The United States of America (USA) are commonly known as the United States (U.S. or US) or America.\")\n",
    "\n",
    "expression = r\"[Uu](nited|\\\\.?) ?[Ss](tates|\\\\.?)\"\n",
    "for match in re.finditer(expression, doc.text):\n",
    "    start, end = match.span()\n",
    "    span = doc.char_span(start, end)\n",
    "    # This is a Span object or None if match doesn't map to valid token sequence\n",
    "    if span is not None:\n",
    "        print(\"Found match:\", span.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fcae3a90-72c7-463f-b78b-a75b3c4b4d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found match: United States\n",
      "Found match: USA\n",
      "Found match: United States\n",
      "Found match: U.S.\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"The United States of America (USA) are commonly known as the United States (U.S. or US) or America.\")\n",
    "\n",
    "expression = r\"(United States|USA|U\\.S\\.|unitedstates|UnitedStates)\"\n",
    "for match in re.finditer(expression, doc.text):\n",
    "    start, end = match.span()\n",
    "    span = doc.char_span(start, end)\n",
    "    # This is a Span object or None if match doesn't map to valid token sequence\n",
    "    if span is not None:\n",
    "        print(\"Found match:\", span.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddb0a06-6019-453b-aded-5099ef2b7493",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f71d27-9a2c-4106-88ae-ac2a6c127650",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
